\begin{savequote}[45mm]
\ascii{Any fool can write code that a computer can understand. Good programmers write code that humans can understand.}
\qauthor{\ascii{- Martin Flower}}
\end{savequote}

\chapter{データ読み込み} 
\label{ch:input-pipeline}

\begin{content}

一般的に、\ascii{TensorFlow}は学習/推論サブグラフにサンプルデータを入力して演算を実行します。サンプルデータを読み込む方法には3つあります：

\begin{enum}
  \eitem{データ注入：\code{feed\_dict}辞書を通じてデータを\code{Session.run}に渡し、\code{Placeholder}の出力\code{Tensor}の値を置き換えます。}
  \eitem{データパイプライン：入力サブグラフを構築し、並行してファイルからサンプルデータを読み込みます。}
  \eitem{データ事前読み込み：小規模なデータセットの場合、\code{Const}または\code{Variable}を使用して直接データを保持します。}
\end{enum}

大規模なデータセットに基づく学習または推論タスクでは、サンプルデータの入力には通常データパイプライン方式が使用され、高いスループットを確保し、学習/推論の実行効率を向上させます。このプロセスではキューを使用して、入力サブグラフと学習/推論サブグラフの間のデータ相互作用と非同期制御を実現します。

本章では、データ読み込みのパイプラインの仕組みに焦点を当て、\ascii{TensorFlow}の並行実行の調整メカニズムと、並行実行におけるキューの役割について詳しく説明します。

\end{content}

\section{データ注入}

\begin{content}

データ注入は最も一般的なデータ読み込み方法です。\code{feed\_dict}辞書を通じてサンプルデータを\code{Session.run}または\code{Tensor.eval}メソッドに渡します。辞書のキーは\code{Tensor}の名前で、値はサンプルデータです。

\ascii{TensorFlow}は辞書内の\code{Tensor}の名前に従って、サンプルデータをその\code{Tensor}の値に置き換えます。


\begin{leftbar}
\begin{python}
x = tf.placeholder(tf.float32, [None, 784])
y_ = tf.placeholder(tf.float32, [None, 10])

with tf.Session():
  batch_xs, batch_ys = mnist.train.next_batch(100)
  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
\end{python}
\end{leftbar}

一般的に、\code{feed\_dict}は任意の\code{Tensor}の値を置き換えることができます。しかし、通常は\code{Placeholder}を使用して、その出力\code{Tensor}の値が未確定であり、\code{feed\_dict}で置き換えられることを示します。

\end{content}

\section{データ事前読み込み}

\begin{content}

\code{Const}または\code{Variable}を使用してデータを直接保持し、データをメモリに事前に読み込んで実行効率を向上させることができます。この方法は小規模なデータセットにのみ適しており、サンプルデータセットが大きい場合、メモリリソースの消費が非常に顕著になります。ここでは\ascii{mnist}データセットを例に、データ事前読み込みの使用方法を説明します。


\begin{leftbar}
\begin{python}
from tensorflow.examples.tutorials.mnist import input_data

data_sets = input_data.read_data_sets('/tmp/mnist/data')
\end{python}
\end{leftbar}

\subsection{Constの使用}

\code{Const OP}の出力\code{Tensor}の値は計算グラフに直接組み込まれます。この\code{Const OP}がグラフ内で複数回使用される場合、重複した冗長データが生成され、不必要なメモリリソースが無駄に消費される可能性があります。


\begin{leftbar}
\begin{python}
with tf.name_scope('input'):
  input_images = tf.constant(data_sets.train.images)
  input_labels = tf.constant(data_sets.train.labels)
\end{python}
\end{leftbar}

\subsection{Variableの使用}

不変かつ学習不要の\code{Variable}を使用して\code{Const}を置き換えることができます。この種類の\code{Variable}が初期化されると、その値を変更できなくなり、\code{Const}の属性を持つようになります。

データ事前読み込みに使用される\code{Variable}と学習に使用される\code{Variable}には違いがあります。\code{trainable=False}が設定され、システムは\code{GraphKeys.TRAINABLE\_VARIABLES}集合に分類しません。学習過程で、システムはそれに対して更新操作を実行しません。

また、この種類の\code{Variable}を構築する際、\code{collections=[]}も設定され、システムは\code{GraphKeys.GLOBAL\_VARIABLES}集合に分類しません。学習過程で、システムはそれに対してチェックポイント操作を実行しません。

不変かつ学習不要の\code{Variable}を作成するために、ここで簡単なファクトリメソッドを書きました。


\begin{leftbar}
\begin{python}
def immutable_variable(initial_value):
  initializer = tf.placeholder(
    dtype=initial_value.dtype,
    shape=initial_value.shape)
  return tf.Variable(initializer, trainable=False, collections=[])
\end{python}
\end{leftbar}

\code{immutable\_variable}は渡された\code{initial\_value}を使用して\code{Placeholder}の型と形状情報を構築し、これを\code{Variable}の初期値として使用します。\code{immutable\_variable}を使用して、データ事前読み込み用の不変の\code{Variable}を作成できます。


\begin{leftbar}
\begin{python}
with tf.name_scope('input'):
  input_images = immutable_variable(data_sets.train.images)
  input_labels = immutable_variable(data_sets.train.labels)
\end{python}
\end{leftbar}

\subsection{バッチ事前読み込み}

パイプラインを構築し、データ事前読み込みの仕組みと組み合わせて、サンプルのバッチ読み込みを実現できます。まず、\code{tf.train.slice\_input\_producer}を使用して、各エポックの開始時に全サンプル空間をランダム化し、サンプルセットからランダムに1つの学習サンプルを採取します。


\begin{leftbar}
\begin{python}
def one(input_xs, input_ys, num_epochs)
  return tf.train.slice_input_producer(
    [input_xs, input_ys], num_epochs=num_epochs)
\end{python}
\end{leftbar}

次に、\code{tf.train.batch}を使用して、毎回1バッチのサンプルデータを取得します。

  
\begin{leftbar}
\begin{python}
def batch(x, y, batch_size)
  return tf.train.batch(
    [x, y], batch_size=batch_size)
\end{python}
\end{leftbar}

\code{Variable}を使用してデータを事前に読み込む場合、以下の方法で1バッチのサンプルデータを取得できます。


\begin{leftbar}
\begin{python}
with tf.name_scope('input'):
  input_images = immutable_variable(data_sets.train.images)
  input_labels = immutable_variable(data_sets.train.labels)

  image, label = one(input_images, input_labels, epoch=1)
  batch_images, batch_labels = batch(image, label, batch_size=100)
\end{python}
\end{leftbar}

実際、\code{tf.train.slice\_input\_producer}はサンプルキューを構築し、\code{QueueRunner}を通じて並行的に\code{Enqueue}操作を実行し、学習サンプルを1つずつサンプルキューに追加します。各イテレーション学習の開始時に、\code{DequeueMany}を呼び出して\code{batch\_size}個のバッチサンプルデータを学習サブグラフに一度に取得します。

\end{content}

\section{データパイプライン}

\begin{content}

典型的なデータ読み込みのパイプラインには、以下のいくつかの重要なデータ処理要素が含まれます：

\begin{enum}
  \eitem{ファイル名キュー：ファイル名リストをこのキューに追加します。}
  \eitem{データ読み込み器：ファイル名キューからファイル名を読み取り（取り出し）、データ形式に応じて適切なファイル読み込み器を選択し、ファイルの記録を解析します。}
  \eitem{デコーダー：ファイル記録をデコードし、データサンプルに変換します。}
  \eitem{前処理器：データサンプルに対して前処理を行います（正規化、白色化など）。}
  \eitem{サンプルキュー：処理済みのサンプルデータをサンプルキューに追加します。}
\end{enum}

\ascii{mnist}データセットを例に、データ形式が\code{TFRecord}であると仮定します。まず、\code{tf.train.string\_input\_producer}を使用して、ファイル名リストを保持する\code{FIFOQueue}キューを構築し（\code{EnqueueMany OP}を実行して）、各エポック内でファイル名リストをランダム化します。

\subsection{ファイル名キューの構築}


\begin{leftbar}
\begin{python}
def input_producer(num_epochs):
  return tf.train.string_input_producer(
    ['/tmp/mnist/train.tfrecords'], num_epochs=num_epochs)
\end{python}
\end{leftbar}

ファイル名キューを構築した後、\code{tf.TFRecordReader}を使用してファイル名キューからファイル名を取得し（取り出し、\code{Dequeue OP}を呼び出して実行）、ファイルからサンプル記録を読み取ります。次に、\code{tf.parse\_single\_example}を使用してサンプルデータを解析します。

\subsection{データ読み込み}

\begin{leftbar}
\begin{python}
def parse_record(filename_queue):
  reader = tf.TFRecordReader()
  _, serialized_example = reader.read(filename_queue)
  features = tf.parse_single_example(
      serialized_example,
      features={
          'image_raw': tf.FixedLenFeature([], tf.string),
          'label': tf.FixedLenFeature([], tf.int64),
      })
  return features
\end{python}
\end{leftbar}

\subsection{デコード}

次に、サンプルデータをデコードし、オプションの前処理プロセスを行い、最終的に学習サンプルを取得します。

\begin{leftbar}
\begin{python}
def decode_image(features):
  image = tf.decode_raw(features['image_raw'], tf.uint8)
  image.set_shape([28*28])

  # Convert from [0, 255] -> [-0.5, 0.5] floats.
  image = tf.cast(image, tf.float32) * (1. / 255) - 0.5
  return image

def decode_label(features):
  label = tf.cast(features['label'], tf.int32)
  return label

def one_example(features):
  return decode_image(features), decode_label(features)
\end{python}
\end{leftbar}

\subsection{サンプルキューの構築}

\code{tf.train.shuffle\_batch}を使用して\code{RandomShuffleQueue}キューを構築し、解析後の学習サンプルをこのキューに追加できます（\code{Enqueue OP}を実行して）。イテレーション実行が開始されると、\code{batch\_size}個のサンプルデータをバッチで取得します（\code{DequeueMany OP}を実行して）。


\begin{leftbar}
\begin{python}
def shuffle_batch(image, label, batch_size):
    # Shuffle the examples and collect them into batch\_size
    # batches.(Uses a RandomShuffleQueue)
    images, labels = tf.train.shuffle_batch(
      [image, label], batch_size=batch_size, num_threads=2,
      capacity=1000 + 3 * batch_size,
      # Ensures a minimum amount of shuffling of examples.
      min_after_dequeue=1000)
    return images, labels
\end{python}
\end{leftbar}

\subsection{入力サブグラフ}

最後に、プログラム全体をつなぎ合わせると、入力サブグラフが構築されます。


\begin{leftbar}
\begin{python}
def inputs(num_epochs, batch_size):
  with tf.name_scope('input'):
    filename_queue = input_producer(num_epochs)
    features = parse_record(filename_queue)
    image, label = one_example(features)
    return shuffle_batch(image, label, batch_size)
\end{python}
\end{leftbar}

\end{content}

\section{データ協調}

\begin{content}

実際、データ読み込みのパイプラインの本質は入力サブグラフを構築し、並行I/O操作を実現することで、学習プロセスがI/O操作によってブロックされないようにし、GPUの利用率を向上させることです。

入力サブグラフでは、データフローの処理がいくつかの段階に分割され、各段階が特定のデータ処理機能を完了します。各段階間はキューを媒介として、データの協調と相互作用を完了します。

以下の図は、典型的なニューラルネットワークの学習モードを示しています。全体のパイプラインは2つのキューを媒介として、3つの段階に分割されています。

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{figures/tf-input-pipeline.png}
\caption{モデル学習のワークフロー}
 \label{fig:tf-input-pipeline}
\end{figure}

\subsection{ステップ1}

\code{string\_input\_producer}は\code{FIFOQueue}のキューを構築します。これは状態を持つ操作です。\code{shuffle}オプションに基づいて、各エポックの開始時にランダムにファイルリストを生成し、それらを一緒にキューに追加します。

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.7\textwidth]{figures/tf-input-pipeline-stage-1.png}
\caption{段階1：モデル学習のワークフロー}
 \label{fig:tf-input-pipeline-stage-1}
\end{figure}

\subsubsection{ランダム化}

まず、\code{filenames}という名前の\code{Const OP}を実行し、その後\code{RandomShuffle}を通じてファイル名リストをランダム化します。

\subsubsection{エポック制御}

エポックのカウントを実現するために、巧妙に設計された\code{epochs}というローカル変数が使用されています。このローカル変数は、同一プロセスの複数のステップ間でのみデータを共有し、学習サブグラフによって更新されることはありません。

\code{Session.run}の前に、システムはローカル変数リストの初期化を実行し、\code{epochs}という名前の\code{Variable}をゼロに初期化します。

エポックのカウント機能は\code{CountUpTo}によって完了します。これは\ascii{C++}の\code{i++}に似た動作をします。\code{Variable}の参照と上限パラメータ\code{limit}を保持します。1回のエポックが経過するごとに\code{Variable}を1増加させ、\code{num\_epochs}に達するまで続けます。

エポック数が\code{num\_epochs}に達すると、\code{CountUpTo}は自動的に\code{OutOfRangeError}例外を投げます。詳細な実装は\code{CountUpToOp}のカーネル実装を参照してください。


\begin{leftbar}
\begin{c++}
template <class T>
struct CountUpToOp : OpKernel {
  explicit CountUpToOp(OpKernelConstruction* ctxt)
    : OpKernel(ctxt) {
    OP_REQUIRES_OK(ctxt, ctxt->GetAttr("limit", &limit_));
  }

  void Compute(OpKernelContext* ctxt) override {
    T before_increment;
    {
      mutex_lock l(*ctxt->input_ref_mutex(0));
      
      // Fetch the old tensor
      Tensor tensor = ctxt->mutable_input(0, true);
      T* ptr = &tensor.scalar<T>()();      
      before_increment = *ptr;
      
      // throw OutOfRangeError if exceed limit
      if (*ptr >= limit_) {
        ctxt->SetStatus(errors::OutOfRange(
            "Reached limit of ", limit_));
        return;
      }
      // otherwise increase 1
      ++*ptr;
    }
    // Output if no error.
    Tensor* out_tensor;
    OP_REQUIRES_OK(ctxt, ctxt->allocate_output(
        "output", TensorShape({}), &out_tensor));
    out_tensor->scalar<T>()() = before_increment;
  }

private:
  T limit_;
};
\end{c++}
\end{leftbar}

\subsubsection{エンキュー操作}

実際には、ファイル名リストをキューに追加する操作は\code{EnqueueMany}を実行します。\code{Assign}が\code{Variable}の値を修正するのと同様に、\code{EnqueueMany}も状態を持つ操作で、キューのハンドルを保持し、キューの状態を直接更新します。

ここで、\code{EnqueueMany}は\code{Session.run}によって実行されます。システムは逆方向にトラバースし、依存する\code{Identity}を見つけ、\code{CountUpTo}に制御依存していることを発見します。この時点でエポックカウントが開始され、\code{num\_epoch}に達するまで続き、\code{OutOfRangeError}例外が投げられます。同時に、\code{Identity}は\code{RandomShuffle}に依存し、ランダム化されたファイル名リストを取得します。

\subsubsection{QueueRunner}

また、\code{tf.train.string\_input\_producer}を呼び出す際、計算グラフに特別な操作である\code{QueueRunner}が登録され、\code{GraphKeys.QUEUE\_RUNNERS}集合に追加されます。\code{QueueRunner}は1つ以上の\code{Enqueue}、\code{EnqueueMany}タイプの操作を保持します。

\subsection{ステップ2}

データ読み込み器はファイル名キューからFIFO順にファイル名を取得し、ファイル名に基づいてファイルの記録を読み取ります。成功すると、その記録をデコードして前処理を行い、データサンプルに変換し、最後にサンプルキューに追加します。

\subsubsection{データ読み込み器}

実際には、\code{ReaderRead}という操作が構築され、これがファイル名キューのハンドルを保持し、キューからFIFO順にファイル名を取得します。

ファイルの形式が\code{TFRecord}であるため、\code{ReaderRead}は\code{TFRecordReader}操作に委託してファイルの読み取りを実行します。最終的に、\code{ReaderRead}の処理によって、シリアル化されたサンプルが得られます。

\subsubsection{デコーダー}

シリアル化されたサンプルを取得した後、適切なデコーダーを使用してデコードし、期待されるサンプルデータを得ます。オプションで、サンプルに対して前処理を行うことができます。例えば、\code{reshape}などの操作です。

\subsubsection{エンキュー操作}

サンプルデータを取得した後、\code{QueueEnqueue}の処理を開始し、サンプルをサンプルキューに追加します。\code{QueueEnqueue}は状態を持つ操作で、サンプルキューのハンドルを保持し、キューの更新を直接行います。

実装上、サンプルキューは\code{RandomShuffleQueue}であり、デキュー操作によってランダムサンプリングを実現します。

\subsubsection{並行実行}

I/Oのスループットを向上させるために、複数の並行したデータ読み込み器とデコーダーのワークフローを起動し、並行的にサンプルをサンプルキューに追加することができます。\code{RandomShuffleQueue}はスレッドセーフであり、並行のエンキューやデキュー操作をサポートしています。

\subsection{ステップ3}

データサンプルが\code{batch\_size}に達すると、学習/推論サブグラフはそのバッチのサンプルデータを取り出し、1回の反復計算（通常、1ステップと呼ばれます）を開始します。

\subsubsection{デキュー操作}

実際には、学習サブグラフは\code{DequeueMany}を使用して1バッチのサンプルデータを取得します。

\subsubsection{反復実行}

一般的に、1回の反復実行には2つの基本的なプロセスが含まれます：順伝播計算と逆伝播勾配計算です。ワーカータスクはパラメータサーバータスクから最新の値をローカルに更新し、順伝播計算を実行して今回の反復の損失を得ます。

次に、今回の反復の損失に基づいて、各\ascii{Variable}の勾配を逆方向に計算し、パラメータサーバータスクに更新します。パラメータサーバータスクは各\code{Variable}の値を更新し、現在の値を各ワーカータスクにブロードキャストします。

\subsubsection{チェックポイント}

パラメータサーバータスクは、耐障害性戦略に基づいて、定期的にチェックポイントを実施します。現在のすべての\code{Variable}のデータ、およびグラフのメタデータ（静的なグラフ構造情報を含む）を外部ストレージデバイスに永続化し、後で計算グラフとすべての\code{Variable}のデータを復元できるようにします。

\subsection{パイプラインの同期}

例えば、\code{FIFOQueue}キューにファイル名リストを追加する際、\code{EnqueueMany}から始まるサブグラフ計算が呼び出されます。これには依存する\code{CountUpTo}の実行が含まれます。\code{CountUpTo}が\code{limit}上限に達すると、自動的に\code{OutOfRangeError}例外が発生します。

メインプログラムの役割を果たす\code{QueueRunner}は、\code{coord.join}が再度投げる\code{OutOfRangeError}例外をキャッチし、直ちに対応するキューを閉じ、そのスレッドの実行を終了します。キューが閉じられた後、エンキュー操作は不正となりますが、デキュー操作は依然として有効です（ただし、キューの要素が空の場合を除きます）。

同様に、下流の操作がキュー（ファイル名キュー）から要素をデキューする際、そのキューの要素が空になると、自動的に\code{OutOfRangeError}例外が発生します。この段階に対応する\code{QueueRunner}はその例外の発生を感知し、例外をキャッチして下流のキュー（サンプルキュー）を閉じ、スレッドの実行を終了します。

パイプラインの最後の段階で、\code{train\_op}がサンプルキューからバッチ学習サンプルをデキューする際、キューが空で、かつキューが閉じられている場合、\code{OutOfRangeError}例外が発生し、最終的に学習タスク全体が停止します。

\end{content}
