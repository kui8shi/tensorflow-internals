\begin{savequote}[45mm]
\ascii{Any fool can write code that a computer can understand. Good programmers write code that humans can understand.}
\qauthor{\ascii{- Martin Flower}}
\end{savequote}

\chapter{キュー} 
\label{ch:queue}

\begin{content}

\ascii{TensorFlow}の\code{Session}はスレッドセーフです。つまり、複数のスレッドが同じ\code{Session}インスタンスを使用し、同じグラフインスタンスの異なる\ascii{OP}を同時に実行できます。\ascii{TensorFlow}実行エンジンは、入力と出力に基づいてグラフをプルーニングし、最小の依存関係のあるサブグラフを得ます。

したがって、マルチスレッドを使用し、同じ\code{Session}インスタンスを使用して、同じグラフインスタンスの異なる\ascii{OP}を同時に実行することで、最終的にサブグラフ間の並行実行が実現されます。

典型的なモデルトレーニングでは、\code{Session}のマルチスレッド並行処理能力を十分に活用し、トレーニングのパフォーマンスを向上させることができます。例えば、入力サブグラフは別のスレッドで実行され、サンプルデータを準備します。一方、トレーニングサブグラフは別のスレッドで実行され、\code{batch\_size}のサイズに応じてトレーニングサンプルを一括で取得し、反復トレーニングプロセスを開始します。

本文では、上記の並行モデルの基盤インフラストラクチャについて説明します。これには、キュー、マルチスレッドコーディネーター、および\code{Enqueue OP}の実行を制御する\ascii{QueueRunner}が含まれます。

\end{content}

\section{キュー}

\begin{content}

\ascii{TensorFlow}の実行エンジンにおいて、\ascii{Queue}は非同期計算を制御する強力なツールです。特に、\ascii{Queue}は特殊な\ascii{OP}であり、\ascii{Variable}と同様に状態を持つ\ascii{OP}の一種です。

同様に、\ascii{Variable}には関連する\ascii{Assign}などの状態を変更する\ascii{OP}があるように、\ascii{Queue}にも関連する\ascii{OP}があります。例えば、\code{Enqueue、Dequeue、EnqueueMany、DequeueMany}などの\ascii{OP}は、直接\ascii{Queue}の状態を変更できます。

\subsection{FIFOQueue}

簡単な例を挙げましょう。まず、\code{FIFOQueue}キューを構築します。次に、計算グラフに\code{EnqueueMany}を追加します。この\ascii{OP}はキューの先頭に1つ以上の要素を追加するために使用されます。さらに、キューから要素を取り出す\code{Dequeue}を追加します。最後に、取り出した要素の値に1を加え、その結果をキューに戻します。計算グラフの実行を開始する前の構造は以下の図のようになります。

\begin{figure}[!h]
\centering
\includegraphics[width=0.9\textwidth]{figures/py-queue-example-1.png}
\caption{グラフ構築期}
 \label{fig:py-queue-example-1}
\end{figure}

\code{EnqueueMany}操作を実行した後の計算グラフの状態は以下の図のようになります。

\begin{figure}[!h]
\centering
\includegraphics[width=0.9\textwidth]{figures/py-queue-example-2.png}
\caption{グラフ実行期：EnqueueManyを1回実行}
 \label{fig:py-queue-example-2}
\end{figure}

最初の\code{Enqueue}を実行した後の計算グラフの状態は以下の図のようになります。

\begin{figure}[!h]
\centering
\includegraphics[width=0.9\textwidth]{figures/py-queue-example-3.png}
\caption{グラフ実行期：Enqueueを1回実行}
 \label{fig:py-queue-example-3}
\end{figure}

\subsection{用途}

キューはモデルトレーニングで重要な役割を果たします。後述するデータ読み込みの\ascii{Pipeline}では、トレーニングモデルは通常\code{RandomShuffleQueue}を使用してサンプルデータを準備します。\ascii{IO}のスループットを向上させるために、マルチスレッドを使用して、サンプルデータを並行してサンプルキューに追加できます。同時に、モデルトレーニングスレッドが\code{train\_op}を反復実行する際、\code{batch\_size}サイズのバッチサンプルデータを一度に取得します。

明らかに、キューは\ascii{Pipeline}プロセスにおいて非同期調整とデータ交換の機能を果たしており、これにより\ascii{Pipeline}の設計と実装に大きな柔軟性をもたらしています。

注意すべき点は、キューがマルチスレッドで最大限の効果を発揮するためには、2つの厄介な問題を解決する必要があることです：

\begin{enum}
  \eitem{すべてのスレッドを同時に停止し、例外報告を処理する方法は？}
  \eitem{並行してキューにサンプルデータを追加する方法は？} 
\end{enum}

そのため、\ascii{TensorFlow}は\code{tf.train.Coordinator}と\code{tf.train.QueueRunner}という2つのクラスを設計し、上記の2つの問題をそれぞれ解決しています。

これら2つのクラスは相互補完的で、\code{Coordinator}は複数のスレッドを同時に停止させ、停止通知を待っているメインプログラムに例外を報告します。一方、\code{QueueRunner}は一連のスレッドを作成し、複数のエンキュー\ascii{OP}（例えば\code{Enqueue、EnqueueMany}）の実行を協調します。

\end{content}

\section{コーディネーター}

\begin{content}

\code{Coordinator}は、一群のスレッドの実行を同時に停止させるためのシンプルなメカニズムを提供します。これには3つの重要なメソッドがあります：

\begin{enum}
\eitem{\code{should\_stop}: 現在のスレッドが終了すべきかどうかを判断します}
\eitem{\code{request\_stop}: すべてのスレッドに停止を要求します}
\eitem{\code{join}: すべてのスレッドが停止するのを待ちます}
\end{enum}

\subsection{使用方法}

一般的に、メインプログラムは以下のパターンで\code{Coordinator}を使用します。

\begin{leftbar}
\begin{python}
# Create a coordinator.
coord = tf.train.Coordinator()

# Create 10 threads that run 'MyLoop()'
threads = [threading.Thread(target=MyLoop, args=(coord,)) 
          for i in xrange(10)]

# Start the threads.
for t in threads:
  t.start()
  
# wait for all of them to stop
coord.join(threads)
\end{python}
\end{leftbar}

任意の子スレッドは、\code{coord.request_stop}を呼び出すことで、他のスレッドに実行停止を通知できます。したがって、各スレッドの反復実行では、事前に\code{coord.should_stop()}をチェックする必要があります。\code{coord.request_stop}が呼び出されると、他のスレッドの\code{coord.should_stop()}は直ちに\code{True}を返します。

一般的に、子スレッドの反復実行メソッドは以下の実装パターンに従います。


\begin{leftbar}
\begin{python}
def MyLoop(coord):
  try
    while not coord.should_stop():
      # ...do something...
  except Exception as e:
    coord.request_stop(e)
\end{python}
\end{leftbar}

\subsection{例外処理}

あるスレッドで例外が発生した場合、\code{coord.request\_stop(e)}を通じて例外の発生を報告できます。

\begin{leftbar}
\begin{python}
try:
  while not coord.should_stop():
    # ...do some work...
except Exception as e:
  coord.request_stop(e)
\end{python}
\end{leftbar}

例外処理コードの重複を避けるために、\code{coord.stop\_on\_exception()}のコンテキストマネージャを使用できます。

\begin{leftbar}
\begin{python}
with coord.stop_on_exception():
  while not coord.should_stop():
    # ...do some work...
\end{python}
\end{leftbar}

この例外は\code{coord.join}でも再度スローされます。したがって、メインプrogramで適切に例外を処理する必要があります。

\begin{leftbar}
\begin{python}
try:
  # Create a coordinator.
  coord = tf.train.Coordinator()

  # Create 10 threads that run 'MyLoop()'
  threads = [threading.Thread(target=MyLoop, args=(coord,)) 
            for i in xrange(10)]

  # Start the threads.
  for t in threads:
    t.start()

  # wait for all of them to stop
  coord.join(threads)
except Exception as e:
  # ...exception that was passed to coord.request\_stop(e)
\end{python}
\end{leftbar}

\subsection{実践：LoopThread}

\end{content}

\section{QueueRunner}

\begin{content}

\code{QueueRunner}インスタンスは1つまたは複数の\code{Enqueue}エンキュー\ascii{OP}を保持し、各\code{Enqueue OP}に対して1つのスレッドを起動します。

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{figures/tf-queue-runner-model.png}
\caption{TensorFlowシステムアーキテクチャ}
 \label{fig:tf-queue-runner-model}
\end{figure}

\subsection{QueueRunnerの登録}

\code{tf.train.add\_queue\_runner}を呼び出して、計算グラフに\code{QueueRunner}インスタンスを登録し、\code{GraphKeys.QUEUE\_RUNNERS}コレクションに追加できます。

\begin{leftbar}
\begin{python}
def add_queue_runner(qr, collection=ops.GraphKeys.QUEUE_RUNNERS):
  ops.add_to_collection(collection, qr)
\end{python}
\end{leftbar}

\subsection{QueueRunnerの実行}

\code{tf.train.start\_queue\_runners}を呼び出すと、計算グラフからすべての\code{QueueRunner}インスタンスを見つけ、\code{QueueRunner}インスタンスからすべての\code{Enqueue OP}を取り出し、各\ascii{OP}に対して1つのスレッドを起動します。

\begin{leftbar}
\begin{python}
def start_queue_runners(sess, coord, daemon=True, start=True,
                        collection=ops.GraphKeys.QUEUE_RUNNERS):
  with sess.graph.as_default():
    threads = []
    for qr in ops.get_collection(collection):
      threads.extend(qr.create_threads(
          sess, coord=coord, daemon=daemon, start=start))
  return threads
\end{python}
\end{leftbar}

\code{QueueRunner.create\_threads}メソッドでは、含まれる各\code{Enqueue}タイプの\ascii{OP}に対して個別のスレッドを起動します。

\begin{leftbar}
\begin{python}
class QueueRunner(object):
  def create_threads(self, sess, coord, daemon, start):
    """Create threads to run the enqueue ops.
    """
    threads = [threading.Thread(
        target=self._run, args=(sess, op, coord))
        for op in self._enqueue_ops]
    if coord:
      threads.append(threading.Thread(
          target=self._close_on_stop, 
          args=(sess, self._cancel_op, coord)))
    for t in threads:
      if coord:
        coord.register_thread(t)
      if daemon:
        t.daemon = daemon
      if start:
        t.start()
    return threads
\end{python}
\end{leftbar}

\subsubsection{Enqueueの反復実行}

各\code{Enqueue}サブスレッドは\code{Enqueue OP}を反復実行します。\code{OutOfRangeError}例外が発生した場合、キューは自動的に閉じられ、サブスレッドは終了します。ただし、他のタイプの例外が発生した場合、\code{Coordinator}に全スレッドの実行停止を通知し、サブスレッドを終了します。

\begin{leftbar}
\begin{python}
class QueueRunner(object):
  def _run(self, sess, enqueue_op, coord):
    try:
      enqueue_callable = sess.make_callable(enqueue_op)
      while True:
        if coord.should_stop():
          break
        try:
          enqueue_callable()
        except errors.OutOfRangeError:  
          sess.run(self._close_op)
          return
    except Exception as e:
      coord.request_stop(e)
\end{python}
\end{leftbar}

\subsubsection{キューの閉鎖}

また、\code{Coordinator}インスタンスが与えられた場合、\code{QueueRunner}は追加で1つのスレッドを起動します。\code{Coordinator}インスタンスの\code{request\_stop}メソッドが呼び出された後、このスレッドは自動的にキューを閉じます。

\begin{leftbar}
\begin{python}
class QueueRunner(object):
  def _close_on_stop(self, sess, cancel_op, coord):
    """Close the queue, and cancel pending enqueue ops
       when the Coordinator requests stop.
    """
    coord.wait_for_stop()
    try:
      sess.run(cancel_op)
    except Exception:
      pass
\end{python}
\end{leftbar}

ここで、\code{Queue}の\code{Cancel OP}と\code{Close OP}はどちらもキューを閉じますが、\code{Cancel OP}はキャッシュされた\code{Enqueue OP}リストを取り消し、\code{Close OP}はキャッシュされた\code{Enqueue OP}リストを保持します。

\subsection{キューの閉鎖後}

キューが閉じられた後、\code{Enqueue}の試行はエラーを生成します。ただし、\code{Dequeue}の試行は、キューに要素が残っている限り成功します。そうでない場合、\code{Dequeue}は即座に失敗し、\code{OutOfRangeError}例外をスローし、より多くの要素がエンキューされるのを待つことはありません。
