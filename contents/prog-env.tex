\begin{savequote}[45mm]
\ascii{Any fool can write code that a computer can understand. Good programmers write code that humans can understand.}
\qauthor{\ascii{- Martin Flower}}
\end{savequote}

\chapter{プログラミング環境} 
\label{ch:prog-env}

\begin{content}

\tf{}の迅速な入門を実現するため、本章では\tf{}のプログラミング環境を紹介します。これにはコード構造、プロジェクトのビルドが含まれ、\tf{}のシステムアーキテクチャについて基本的な感覚的理解を確立することを目的としています。

\end{content}

\section{コード構造}

\begin{content}

\subsection{ソースコードのクローン}

まず、\ascii{Github}から\tf{}のソースコードをクローンします。

\begin{leftbar}
\begin{python}
$ git clone git@github.com:tensorflow/tensorflow.git
\end{python}
\end{leftbar}

次に、最新の安定ブランチに切り替えます。例えば、\code{r1.4}ブランチです。

\begin{leftbar}
\begin{python}
$ cd tensorflow
$ git checkout r1.4
\end{python}
\end{leftbar}

\subsection{ソースコード構造}

以下のコマンドを実行して、\tf{}ソースコードの組織構造を表示します。

\begin{leftbar}
\begin{python}[]
$ tree -d -L 1 ./tensorflow
\end{python}
\end{leftbar}

このうち、本書では主に\code{core, python}コンポーネントに焦点を当て、一部\code{c, cc, stream\_executor}コンポーネントにも触れます。

\begin{leftbar}
\begin{c++}[caption={TensorFlowソースコード構造}]
./tensorflow
├── c
├── cc
├── compiler
├── contrib
├── core
├── docs_src
├── examples
├── g3doc
├── go
├── java
├── python
├── stream_executor
├── tools
└── user_ops
\end{c++}
\end{leftbar}

現在の最新リリースである\ascii{1.4}バージョンまでに、\tf{}のコードベースは約\ascii{100}万行のコードを持っています。これには\ascii{53}万行の\ascii{C/C++}コード、\ascii{37}万行の\ascii{Python}コードが含まれており、コードの規模は拡大し続けています。\ascii{Python}が提供する\ascii{API}が最も完成度が高く、他のプログラミング言語の\ascii{API}はまだ成熟していないか、あるいは開発の初期段階にあります。

\begin{leftbar}
\begin{python}[caption={TensorFlowコード統計}]
-------------------------------------------------------
Language             files    blank    comment    code
-------------------------------------------------------
C++                   2238    77610     68275    443099
Python                1881    92018    151807    369399
C/C++ Header          1175    27392     46215     86691
Markdown               218     8859         2     30925
CMake                   50     2183       986     16398
Go                      28     1779     13290     15003
Java                    72     1789      3111      7779
Bourne Shell           103     1487      3105      6074
Protocol Buffers        87     1313      3339      3452
Objective C++            9      227       181      1201
C                        8      157       130       941
make                     4      105       136       612
XML                     25      135       265       315
Groovy                   3       46        74       246
Maven                    5       21         4       245
DOS Batch                9       30         0       143
Dockerfile               7       41        69       133
Perl                     2       29        38       130
Bourne Again Shell       3       24        63       111
JSON                     3        0         0        23
Objective C              1       10        13        21
YAML                     1        3        24        15
-------------------------------------------------------
SUM:                  5932   215258    291127    982956
-------------------------------------------------------
\end{python}
\end{leftbar}

\subsection{Core}

内部コアのソースコード構造は以下の通りで、主にプラットフォーム、ユーティリティライブラリ、基本フレームワーク、\ascii{Protobuf}定義、ローカルランタイム、分散ランタイム、グラフ操作、\ascii{OP}定義、および\ascii{Kernel}実装などで構成されています。これは本書で重点的に分析するコンポーネントの一つであり、基本フレームワークに隠れているドメインモデルを掘り下げ、ランタイム環境全体のライフサイクルとグラフ操作の詳細なプロセスを追跡し、一般的な\ascii{OP}の\ascii{Kernel}実装原理と動作メカニズムを明らかにします。

\begin{leftbar}
\begin{c++}[caption={Coreソースコード構造}]
./tensorflow/core
├── common_runtime
├── debug
├── distributed_runtime
├── example
├── framework
├── graph
├── grappler
├── kernels
├── lib
├── ops
├── platform
├── profiler
├── protobuf
├── public
├── user_ops
└── util
\end{c++}
\end{leftbar}

このうち、\code{core}は主に\code{C++}で実装されており、約\ascii{26}万行のコードがあります。

\begin{leftbar}
\begin{python}[caption={Coreコード統計}]
-------------------------------------------------------
Language             files    blank   comment      code
-------------------------------------------------------
C++                   1368    44791     38968    259289
C/C++ Header           653    15040     24474     50506
Protocol Buffers        57      736      2371      1806
Markdown                11      327         0      1285
JSON                     2        0         0        18
-------------------------------------------------------
SUM:                  2091    60894     65813    312904
-------------------------------------------------------
\end{python}
\end{leftbar}

\subsection{Python}

\ascii{Python}は\tf{}のプログラミングモデルを定義・実装し、外部に\ascii{API}を公開してプログラマーが使用できるようにしています。そのソースコード構造は以下の通りで、これも本書で重点的に分析する部分です。

\begin{leftbar}
\begin{c++}[caption={Pythonソースコード構造}]
./tensorflow/python
├── client
├── debug
├── estimator
├── feature_column
├── framework
├── grappler
├── kernel_tests
├── layers
├── lib
├── ops
├── platform
├── profiler
├── saved_model
├── summary
├── tools
├── training
├── user_ops
└── util
\end{c++}
\end{leftbar}

このコンポーネントは\code{Python}で実装されており、約\ascii{18}万行のコードがあります。

\begin{leftbar}
\begin{python}[caption={Pythonコード統計}]
-------------------------------------------------------
Language            files     blank   comment      code
-------------------------------------------------------
Python                714     45769     69407    179565
C++                    20       496       506      3658
C/C++ Header           15       207       387       363
Markdown                4        48         0       200
Protocol Buffers        3        16        10        71
Bourne Shell            1        13        28        68
-------------------------------------------------------
SUM:                  757     46549     70338    183925
-------------------------------------------------------
\end{python}
\end{leftbar}

\subsection{Contrib}

\code{contrib}はサードパーティが貢献したプログラミングライブラリで、\tf{}の標準化前の実験的プログラミングインターフェイスでもあります。\ascii{Boost}コミュニティと\ascii{C++}標準の関係に似ています。\code{contrib}のインターフェイスが成熟すると、\tf{}によって標準化され、\code{contrib}から\code{core, python}に移行され、正式にリリースされます。

\begin{leftbar}
\begin{python}[caption={Contribソースコード構造}]
./tensorflow/contrib
├── android
├── batching
├── bayesflow
├── benchmark_tools
├── boosted_trees
├── cloud
├── cluster_resolver
├── cmake
├── compiler
├── copy_graph
├── crf
├── cudnn_rnn
├── data
├── decision_trees
├── deprecated
├── distributions
├── eager
├── factorization
├── ffmpeg
├── framework
├── fused_conv
├── gdr
├── graph_editor
├── grid_rnn
├── hooks
├── hvx
├── image
├── imperative
├── input_pipeline
├── integrate
├── keras
├── kernel_methods
├── labeled_tensor
├── layers
├── learn
├── legacy_seq2seq
├── linalg
├── linear_optimizer
├── lookup
├── losses
├── makefile
├── memory_stats
├── meta_graph_transform
├── metrics
├── mpi
├── nccl
├── ndlstm
├── nearest_neighbor
├── nn
├── opt
├── pi_examples
├── predictor
├── quantization
├── reduce_slice_ops
├── remote_fused_graph
├── resampler
├── rnn
├── saved_model
├── seq2seq
├── session_bundle
├── signal
├── slim
├── solvers
├── sparsemax
├── specs
├── staging
├── stat_summarizer
├── stateless
├── tensor_forest
├── tensorboard
├── testing
├── text
├── tfprof
├── timeseries
├── tpu
├── training
├── util
├── verbs
└── xla_tf_graph
\end{python}
\end{leftbar}

\tf{}コミュニティは非常に活発であり、\code{contrib}の変更は頻繁に行われています。\ascii{1.4}バージョンまでに、約\ascii{23}万行のコードがあり、主に\ascii{Python}で設計・実装されたプログラミングインターフェイスで、一部のランタイムは\ascii{C++}で実装されています。

\begin{leftbar}
\begin{python}[caption={Contribコード統計}]
-------------------------------------------------------
Language            files     blank   comment      code
-------------------------------------------------------
Python               1007     41436     75096    170355
C++                   201      5500      5313     32944
CMake                  48      2172       955     16358
C/C++ Header           99      1875      2867      6583
Markdown               46      1108         0      3485
Bourne Shell           18       232       386      1272
C                       7       151       118       931
Protocol Buffers       20       224       454       680
make                    4       105       136       612
Java                    2        77       209       335
Groovy                  1        10        20        75
Bourne Again Shell      1         6        15        59
Dockerfile              1         2         1        14
XML                     2         3         0         9
-------------------------------------------------------
SUM:                 1457     52901     85570    233712
-------------------------------------------------------
\end{python}
\end{leftbar}

\subsection{StreamExecutor}

\ascii{StreamExecutor}は\ascii{Google}の別のオープンソースコンポーネントライブラリで、ホスト側(\ascii{host-side})のプログラミングモデルとランタイム環境を提供し、\ascii{CUDA}と\ascii{OpenCL}の統一的なラッパーを実装しています。これにより、ホスト側のコードで\ascii{Kernel}関数を\code{CUDA}または\code{OpenCL}の計算デバイスにシームレスにデプロイして実行することができます。

現在、\ascii{StreamExecutor}は\ascii{Google}内部の\ascii{GPGPU}アプリケーションのランタイムに広く適用されています。\tf{}ランタイムにも\ascii{StreamExecutor}のスナップショットバージョンが含まれており、\ascii{CUDA}と\code{OpenCL}のランタイムをラップするために使用されています。本書では\ascii{CUDA}のプログラミングモデルとスレッドモデルを簡単に紹介し、\ascii{StreamExecutor}のシステムアーキテクチャと動作原理を詳しく説明し、\ascii{Kernel}関数の実装パターンとイディオムを明らかにします。

\begin{leftbar}
\begin{c++}[caption={StreamExecutorソースコード構造}]
./tensorflow/stream_executor
├── cuda
├── host
├── lib
└── platform
\end{c++}
\end{leftbar}

\ascii{StreamExecutor}は\code{C++}で実装されており、約\ascii{2.5}万行のコードがあります。

\begin{leftbar}
\begin{python}[caption={StreamExecutorコード統計}]
-------------------------------------------------------
Language            files     blank   comment      code
-------------------------------------------------------
C++                    43      2440      1196     16577
C/C++ Header           81      2322      5080      8625
-------------------------------------------------------
SUM:                  124      4762      6276     25202
-------------------------------------------------------
\end{python}
\end{leftbar}

\subsection{Compiler}

周知の通り、柔軟性は\tf{}の最も重要な設計目標であり、核心的な利点です。そのため、\tf{}のシステムアーキテクチャは優れた拡張性を持っています。\tf{}は任意のグラフ構造を定義でき、異種の計算デバイスを効果的に実行できます。しかし、二兎を追う者は一兎も得ずで、低レベルの\ascii{OP}が計算サブグラフに組み合わされ、\ascii{GPU}上で効果的に実行することを期待する場合、ランタイムはより多くの\ascii{Kernel}演算を開始します。

したがって、\tf{}の\ascii{OP}分解・組合せ方法は、ランタイムで最も効果的な方法で実行されることを保証できません。このとき、\ascii{XLA}技術が生まれました。これは\ascii{JIT}コンパイル技術を使用してランタイムの計算グラフを分析し、複数の\ascii{OP}を融合させ、より効率的なネイティブマシンコードを生成して、計算グラフの実行効率を向上させます。

\begin{leftbar}
\begin{python}[caption={Compilerソースコード構造}]
./tensorflow/compiler
├── aot
├── jit
├── plugin
├── tests
├── tf2xla
└── xla
\end{python}
\end{leftbar}

\ascii{XLA}技術は現在、初期の研究開発段階にあり、\tf{}コミュニティで活発に研究されている方向性の一つです。現在のコード規模は約\ascii{12.5}万行で、主に\ascii{C++}で実装されています。

\begin{leftbar}
\begin{python}[caption={Compilerコード統計}]
-------------------------------------------------------
Language            files     blank   comment      code
-------------------------------------------------------
C++                   455     19010     18334    102537
C/C++ Header          250      5939     10323     15510
Python                 37      1255      1416      6446
Protocol Buffers        5       312       501       781
Markdown                2         0         0         3
-------------------------------------------------------
SUM:                  749     26516     30574    125277
-------------------------------------------------------
\end{python}
\end{leftbar}

\end{content}

\section{プロジェクトのビルド}

\begin{content}

始める前に、\tf{}ソースコードのビルドプロセスを試し、\tf{}の基本的なビルド方法、ツール、および依存するコンポーネントライブラリ、サードパーティツールキットを理解することは、\tf{}の動作原理を理解する上で大きな助けとなります。ただし、紙幅の制限があるため、本章では\ascii{Mac OS}システムを例に、\tf{}のソースコードのコンパイル、インストール、および検証プロセスについてのみ説明します。他のオペレーティングシステムについては、\tf{}が公開している公式ドキュメントを参照してください。

\subsection{環境準備}

\ascii{TensorFlow}のフロントエンドは多言語をサポートするプログラミングインターフェイスです。したがって、\ascii{TensorFlow}のソースコードをコンパイルする前に、関連するコンパイラ、インタプリタ、およびランタイム環境を事前にインストールする必要があります。例えば、\ascii{Python}をプログラミングインターフェイスとして使用する場合、事前に\ascii{Python}インタプリタをインストールする必要があります。次に、ビルドシステムの前に、\ascii{GCC}や\ascii{Clang}などの\ascii{C++}コンパイラを事前にインストールする必要があります。これはバックエンドシステムの実装をコンパイルするために使用されます。\ascii{TensorFlow}は\ascii{C++11}構文を使用して実装されているため、インストールする\ascii{C++}コンパイラが\ascii{C++11}をサポートしていることを確認する必要があります。また、\ascii{TensorFlow}は\ascii{Bazel}ビルドツールを使用しており、これをより高度な抽象化された\ascii{Make}ツールと見なすことができます。残念ながら、\ascii{Bazel}は\ascii{Java8}で実装されており、\ascii{JDK}に依存しています。したがって、\ascii{Bazel}をインストールする前に、\ascii{1.8}以上のバージョンの\ascii{JDK}を事前にインストールする必要があります。

\subsubsection{JDKのインストール}

\ascii{Oracle}の公式ウェブサイトから\ascii{1.8}バージョンの\ascii{JDK}をダウンロードすることをお勧めします。その後、関連する環境変数を作成し、\code{～/.bashrc}設定ファイルに追加します。

\begin{leftbar}
\begin{python}
$ echo 'export JAVA_HOME=$(/usr/libexec/java_home)' >> ~/.bashrc
$ echo 'export PATH="$JAVA_HOME/bin:$PATH"' >> ~/.bashrc
\end{python}
\end{leftbar}

\subsubsection{Bazelのインストール}

\ascii{Mac OS}では、\ascii{brew}を使用して\ascii{Bazel}をインストールできます。

\begin{leftbar}
\begin{python}
$ brew install bazel
\end{python}
\end{leftbar}

システムに\ascii{brew}がインストールされていない場合は、以下のコマンドを実行して\ascii{brew}をインストールできます。もちろん、\ascii{brew}をインストールするには事前に\ascii{Ruby}インタプリタをインストールする必要がありますが、ここでは詳しく説明しません。

\begin{leftbar}
\begin{python}
$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
\end{python}
\end{leftbar}

\subsubsection{Swigのインストール}

\ascii{TensorFlow}は\ascii{Swig}を使用して多言語プログラミング環境を構築し、関連するプログラミング言語のラッパーを自動生成します。したがって、ビルド前に\ascii{Swig}ツールキットをインストールする必要があります。

\begin{leftbar}
\begin{python}
$ brew install swig
\end{python}
\end{leftbar}

\subsubsection{Python依存パッケージのインストール}

\ascii{pip}を使用して\ascii{TensorFlow}が依存する\ascii{Python}パッケージをインストールします。

\begin{leftbar}
\begin{python}
$ sudo pip install six numpy wheel autograd
\end{python}
\end{leftbar}

システムに\ascii{pip}がインストールされていない場合は、\ascii{brew}を使用して事前に\ascii{pip}をインストールできます。

\begin{leftbar}
\begin{python}
$ brew install pip
\end{python}
\end{leftbar}

\subsubsection{CUDAツールキットのインストール}

システムに計算互換性が\ascii{3.0}以上の\ascii{GPU}カードがインストールされている場合、\ascii{CUDA}ツールキットおよび\ascii{cuDNN}をインストールして、\tf{}ランタイムの\ascii{GPU}アクセラレーションを実現する必要があります。\ascii{NVIDIA}の公式ウェブサイトから\ascii{CUDA Toolkit 8}以上のバージョンをダウンロードし、システムにインストールし、関連する環境変数を設定することをお勧めします。

\begin{leftbar}
\begin{python}
$ echo 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc
$ echo 'export LD_LIBRARY_PATH=$CUDA_HOME/lib:$LD_LIBRARY_PATH' >> ~/.bashrc
\end{python}
\end{leftbar}

その後、\ascii{cuDNN 5.1}以上のバージョンをダウンロードし、\code{CUDA\_HOME}関連のシステムディレクトリに解凍します。

\begin{leftbar}
\begin{python}
$ sudo tar -xvf cudnn-8.0-macos-x64-v5.1.tgz -C /usr/local
\end{python}
\end{leftbar}

\subsection{設定}

これで、コンパイル環境が整いました。\code{./configure}を実行して\ascii{TensorFlow}のコンパイル環境を設定します。システムが\ascii{GPU}をサポートしている場合は、関連する\ascii{CUDA/cuDNN}コンパイル環境を設定する必要があります。

\begin{leftbar}
\begin{python}
$ ./configure
\end{python}
\end{leftbar}

\subsection{ビルド}

設定が成功したら、\ascii{Bazel}を使用して\ascii{TensorFlow}のコンパイルを開始します。コンパイルが開始される前に、コードリポジトリから関連する依存ライブラリのソースコードをダウンロードしようとします。これには\ascii{gRPC, Protobuf, Eigen}などが含まれ、自動的にコンパイルが完了します。

\begin{leftbar}
\begin{python}
$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
\end{python}
\end{leftbar}

\ascii{GPU}計算をサポートする場合は、\code{--config=cuda}コンパイルオプションを追加します。

\begin{leftbar}
\begin{python}
$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
\end{python}
\end{leftbar}

コンパイルが成功したら、\ascii{TensorFlow}の\ascii{Wheel}パッケージを構築できます。

\begin{leftbar}
\begin{python}
$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
\end{python}
\end{leftbar}

\subsection{インストール}

\ascii{Wheel}パッケージの構築が成功したら、\ascii{pip}を使用して\ascii{TensorFlow}をシステムにインストールします。

\begin{leftbar}
\begin{python}
$ sudo pip install /tmp/tensorflow_pkg/tensorflow-1.4.0-py2-none-any.whl
\end{python}
\end{leftbar}

\subsection{検証}

\ascii{Python}インタプリタを起動して、\ascii{TensorFlow}のインストールが成功したかどうかを確認します。

\begin{leftbar}
\begin{python}
$ python
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
>>> print(sess.run(hello))
Hello, TensorFlow!
\end{python}
\end{leftbar}

\subsection{IDE}

コードを読む前に、適切な\ascii{IDE}を選択することで、コードの読解の質とスピードを向上させることができます。\ascii{C++}コードを読むには\ascii{Eclipse CDT}を、\ascii{Python}コードを読むには\code{PyDev}プラグインをインストールすることをお勧めします。同時に、\ascii{JetBrains}が提供する\ascii{Clion}で\ascii{C++}を読み、\ascii{PyCharm}で\ascii{Python}を読むことも推奨します。ただし、\ascii{C++}コードを読む際には、\ascii{TensorFlow, CUDA, Eigen3}のヘッダーファイルの検索ディレクトリを設定し、関連する事前定義マクロを追加する必要があります。これにより、\code{IDE}がコード内のシンボルを正しく解析できるようになります。本章では\ascii{Eclipse CDT}を例に、関連する設定方法を説明します。

\subsubsection{Eclipseプロジェクトの作成}

\refig{setup-eclipse}に示すように、\ascii{Eclipse C++}プロジェクトを作成します。一意のプロジェクト名を決定し、手動で\ascii{TensorFlow}ソースコードのルートディレクトリを指定し、\ascii{Makefile}の空プロジェクトを選択します。次に、\ascii{Properties > C/C++ General > Paths and Symbols > Includes}に従ってヘッダーファイルの検索ディレクトリを設定します。

\begin{table}[!htbl]
\resizebox{0.95\textwidth}{!} {
\begin{tabular*}{1.2\textwidth}{@{}ll@{}}
\toprule
\ascii{設定項目} & \ascii{ディレクトリ} \\
\midrule
\ascii{TensorFlow} & \code{/usr/local/lib/python2.7/site-packages/tensorflow/include} \\
\ascii{CUDA} & \code{/usr/local/cuda/include} \\ 
\bottomrule
\end{tabular*}
}
\caption{ヘッダーファイル検索ディレクトリ}
\label{tbl:tf-includes}
\end{table}

\begin{figure}[!htbl]
\centering
\includegraphics[width=0.75\textwidth]{figures/setup-eclipse.png}
\caption{Eclipse C++プロジェクトの作成}}
 \label{fig:setup-eclipse}
\end{figure}

\subsubsection{Eigenの設定}

残念ながら、\ascii{Eigen}が公開しているヘッダーファイルには\code{.h}の拡張子がなく、\ascii{CDT}は関連するシンボルを解析できません。\code{\href{http://eigen.tuxfamily.org/index.php?title=IDEs}{http://eigen.tuxfamily.org/index.php?title=IDEs}}の関連説明を参照し、\ascii{Preferences > C/C++ > Coding Style > Organize Includes > Header Substitution}に従って\code{eigen-header-substitution.xml}ファイルをインポートしてください。\refig{eclipse-eigen3}に示すとおりです。

\begin{figure}[!htbl]
\centering
\includegraphics[width=0.75\textwidth]{figures/eclipse-eigen3.png}
\caption{\ascii{Eigen}のヘッダーファイルの置換}
 \label{fig:eclipse-eigen3}
\end{figure}

\end{content}

\section{コード生成}

\begin{content}

\ascii{TensorFlow}システムをビルドする際、\ascii{Bazel}や\ascii{CMake}が自動的に一部のソースコードを生成します。コードジェネレータの出力結果を理解することで、システムの動作パターンへの理解を深めることができます。

\end{content}

\section{技術スタック}

\begin{content}

\refig{tf-stack}に示すように、システムの階層構造に従って\tf{}の技術スタックを表示しており、これが\tf{}エコシステムの核心を形成しています。

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{figures/tf-stack.png}
\caption{TensorFlow技術スタック}}
 \label{fig:tf-stack}
\end{figure}

\end{content}
