\begin{savequote}[45mm]
\ascii{Any fool can write code that a computer can understand. Good programmers write code that humans can understand.}
\qauthor{\ascii{- Martin Flower}}
\end{savequote}

\chapter{ローカル実行} 
\label{ch:local}

\begin{content}

\tf{}は1つのプロセス内で独立して実行され、計算グラフの実行プロセスを完了することができます。本章ではローカル実行時の基本的なアーキテクチャと実行メカニズムを重点的に紹介します。計算グラフの剪定、分割、最適化、実行などの実装技術の詳細について重点的に議論し、ローカルモードでのデバイス間の\ascii{OP}間のデータ交換の仕組みや、デバイスセット上での\ascii{OP}の配置(\ascii{placement})アルゴリズムについて詳しく探ります。

\end{content}

\section{ローカルモード}
\label{sec:local-runtime}

\begin{content}

\refig{local}に示すように、ローカルモードでは\ascii{Client, Master, Worker}が同じマシンの同じプロセス内に配置され、\code{DirectSession}がこれら3つの役割を同時に担います。\code{DirectSession}は独立したプロセス内で実行され、各サービスエンティティ間は関数呼び出しの関係にあります。

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{figures/local.png}
\caption{ローカルモード}
 \label{fig:local}
\end{figure}

\ascii{Client}は計算グラフの構築を担当し、\code{Session.run}を呼び出すことで計算グラフの実行プロセスを開始します。\refig{local-runtime}に示すように、\code{run\_step}の実行プロセスには、計算グラフの剪定、分割、実行という3つの重要な段階が含まれています。

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/local-runtime.png}
\caption{ローカルモード：グラフ操作}
 \label{fig:local-runtime}
\end{figure}

\subsection{部分実行}

\ascii{Master}は計算グラフの実行コマンドを受け取ると、計算グラフの剪定操作を開始します。計算グラフの入力出力に基づいてグラフを逆方向にトラバースし、最小の依存関係を持つサブグラフを探し、これを\code{ClientGraph}と呼びます。

つまり、\code{run\_step}を実行するたびに、全体の計算グラフ(\code{FullGraph})を実行するのではなく、部分的なサブグラフを実行します。剪定は\tf{}の部分実行の設計思想を体現しています。

\subsection{並列実行}

次に、ランタイムは現在のデバイスセットに基づいてグラフを分割し、多くのサブグラフを生成します。各サブグラフは\code{PartitionGraph}と呼ばれます。そして各\ascii{Worker}が各\code{PartitionGraph}を並列に実行します。各\ascii{PartitionGraph}に対して、ランタイムは\ascii{Executor}を起動し、そのトポロジカル順序に従って\code{PartitionGraph}の実行を完了します。

つまり、分割と実行は\tf{}の並列実行の設計思想を体現しています。

\section{セッション制御}

ローカルモードでは、ランタイムは\code{DirectSession}によって制御されます。一般的に、\code{DirectSession}が計算グラフを実行する際、各コンポーネント間はすべて関数呼び出しの関係にあります。しかし、\code{DirectSession}には明確なライフサイクル管理メカニズムも存在します。\refig{local-direct-session-lifecycle}に示すとおりです。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/local-direct-session-lifecycle.png}
\caption{DirectSessionのライフサイクル}
 \label{fig:local-direct-session-lifecycle}
\end{figure}

\subsection{ドメインモデル}

\refig{local-direct-session-model}に示すように、\code{DirectSession}は\code{SimpleGraphExecutionState}インスタンスを保持し、後者は計算グラフの剪定を担当し、\code{ClientGraph}インスタンスを生成します。

\code{DirectSession}は同時に一群のスレッドプールを保持しますが、毎回\code{DirectSession.run}が実行されるときに、外部の設定に基づいてスレッドプールグループから1つを選択してサービスを提供します。\code{DirectSession}はスレッドセーフであり、複数の並列実行\code{DirectSession.run}をサポートしています。つまり、複数のスレッドプールインスタンスを同時に実行できます。

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/local-direct-session-model.png}
\caption{DirectSessionドメインモデル}
 \label{fig:local-direct-session-model}
\end{figure}

\subsection{セッションの作成}

\refig{local-direct-session-factory}に示すように、\code{DirectSession}は\code{DirectSessionFactory}によって多態的に作成されます。\code{DeviceFactory::AddDevices}がローカルデバイスセットを作成します。

\code{DirectSession}内では主にスレッドプールグループの作成が完了します。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/local-direct-session-factory.png}
\caption{DirectSessionの多態的作成}
 \label{fig:local-direct-session-factory}
\end{figure}

\begin{leftbar}
\begin{c++}
struct DirectSessionFactory : SessionFactory {
  bool AcceptsOptions(const SessionOptions& options) override {
    return options.target.empty();
  }

  Session* NewSession(const SessionOptions& options) override {
    std::vector<Device*> devices;
    DeviceFactory::AddDevices(
        options, "/job:localhost/replica:0/task:0", &devices);
    return new DirectSession(options, new DeviceMgr(devices));
  }
};
\end{c++}
\end{leftbar}

\code{DirectSessionFactory::NewSession}は\ascii{C API}によって呼び出されます。

\begin{leftbar}
\begin{c++}
Status NewSession(const SessionOptions& options, Session** out_session) {
  SessionFactory* factory;
  Status s = SessionFactory::GetFactory(options, &factory);
  if (!s.ok()) {
    *out_session = nullptr;
    return s;
  }
  *out_session = factory->NewSession(options);
  if (!*out_session) {
    return errors::Internal("Failed to create session.");
  }
  return Status::OK();
}

TF_DeprecatedSession* TF_NewDeprecatedSession(
  const TF_SessionOptions* opt, TF_Status* status) {
  Session* session;
  status->status = NewSession(opt->options, &session);
  if (status->status.ok()) {
    return new TF_DeprecatedSession({session});
  } else {
    return nullptr;
  }
}
\end{c++}
\end{leftbar}

\code{DirectSession}のコンストラクタでは、主にそのドメインモデルの初期化を担当し、スレッドプールの作成、\code{CancellationManager}インスタンスの構築が含まれます。

\begin{leftbar}
\begin{c++}
DirectSession::DirectSession(
    const SessionOptions& options,
    const DeviceMgr* device_mgr)
    : options_(options),
      device_mgr_(device_mgr),
      cancellation_manager_(new CancellationManager()) {
  // thread\_pools\_ = ... 
}
\end{c++}
\end{leftbar}

\subsection{セッションの破棄}

\ascii{SessionFactory}によって\code{new}された\code{DirectSession}は、\ascii{C API}によって\code{delete}されます。

\begin{leftbar}
\begin{c++}
void TF_DeleteDeprecatedSession(TF_DeprecatedSession* s, TF_Status* status) {
  status->status = Status::OK();
  delete s->session;  // delete DirectSession
  delete s;
}
\end{c++}
\end{leftbar}

その後、\code{DirectSession}のデストラクタが呼び出され、管理下にあるシステムリソースのクリーンアップを担当します。主に\code{Executor}リスト、\code{ThreadPool}リスト、\code{CancellationManager}インスタンスが含まれます。

\begin{leftbar}
\begin{c++}
DirectSession::~DirectSession() {
  for (auto& it : partial_runs_) {
    it.second.reset(nullptr);
  }
  
  for (auto& it : executors_) {
    it.second.reset();
  }
  
  for (auto d : device_mgr_->ListDevices()) {
    d->op_segment()->RemoveHold(session_handle_);
  }
  
  delete cancellation_manager_;
  
  for (const auto& p_and_owned : thread_pools_) {
    if (p_and_owned.second) delete p_and_owned.first;
  }

  execution_state_.reset(nullptr);
  flib_def_.reset(nullptr);
}
\end{c++}
\end{leftbar}

\subsection{グラフの作成/拡張}

グラフの最初の拡張は、グラフの作成と同等です。グラフの拡張とは、既存の計算グラフをベースに、新しいサブグラフを追加することです。もちろん、追加されるサブグラフに含まれるノードは、元の計算グラフには存在しないはずです。

\begin{leftbar}
\begin{c++}
Status DirectSession::Create(const GraphDef& graph) {
  if (graph.node_size() > 0) {
    mutex_lock l(graph_def_lock_);
    return ExtendLocked(graph);
  }
  return Status::OK();
}

Status DirectSession::Extend(const GraphDef& graph) {
  mutex_lock l(graph_def_lock_);
  return ExtendLocked(graph);
}
\end{c++}
\end{leftbar}

計算グラフを作成する際、\code{DirectSession}は主に\code{SimpleGraphExecutionState}インスタンスの作成を完了します。\refig{local-simple-graph-execution-state-model}に示すように、\code{SimpleGraphExecutionState}インスタンスは\code{FullGraph}の2つの形式のインスタンス：\code{Graph}と\code{GraphDef}を保持し、\code{FullGraph}のライフサイクルの管理と維持を担当します。

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/local-simple-graph-execution-state-model.png}
\caption{SimpleGraphExecutionStateインスタンスの作成}
 \label{fig:local-simple-graph-execution-state-model}
\end{figure}

\code{SimpleGraphExecutionState}の主な責務には以下が含まれます：

\begin{enum}
  \eitem{\code{FullGraph}の構築}：\code{DirectSession.Create}で発生します；
  \eitem{シンプルな\ascii{OP}配置アルゴリズムの実行}：\code{DirectSession.Create}で発生します；
  \eitem{グラフの剪定操作の実行}：\code{DirectSession.Run}で発生します。
\end{enum}

\code{DirectSession::Create}を実行すると、\code{SimpleGraphExecutionState}インスタンスが作成され、\code{FullGraph}インスタンスの構築と初期化が完了します。

\begin{leftbar}
\begin{c++}
Status SimpleGraphExecutionState::MakeForBaseGraph(
    GraphDef* graph_def, const SimpleGraphExecutionStateOptions& opts,
    std::unique_ptr<SimpleGraphExecutionState>* out_state) {
  auto ret = std::make_unique<SimpleGraphExecutionState>(graph_def, opts));

  AddDefaultAttrsToGraphDef(&ret->original_graph_def_, *ret->flib_def_, 0));
  if (!ret->session_options_->config.graph_options().place_pruned_graph()) {
    ret->InitBaseGraph();
  }
  *out_state = std::move(ret);
  return Status::OK();
}
\end{c++}
\end{leftbar}

\code{SimpleGraphExecutionState::InitBaseGraph}は\code{FullGraph}を\code{GraphDef}から\code{Graph}形式に変換し、\code{SimplePlacer}の\ascii{OP}配置アルゴリズムを起動します。

\begin{leftbar}
\begin{c++}
Status SimpleGraphExecutionState::InitBaseGraph() {
  auto ng = std::make_unique<Graph>(OpRegistry::Global());

  GraphConstructorOptions opts;
  ConvertGraphDefToGraph(opts, *original_graph_def_, ng.get());

  SimplePlacer placer(ng.get(), device_set_, session_options_);
  placer.Run();

  this->graph_ = ng.release();
  return Status::OK();
}
\end{c++}
\end{leftbar}

\subsubsection{グラフ構築：GraphDef -> Graph}

最初、\code{SimpleGraphExecutionState}が得るのは\code{GraphDef}で、これは最も原始的なグラフ構造です。これは\ascii{Client}が直列化して後端\ascii{C++}に渡し、後端で逆直列化して得られたグラフ構造です。

\refig{local-graph-def-to-graph}に示すように、\code{ConvertGraphDefToGraph}を呼び出して\code{GraphDef}インスタンスを等価な\code{Graph}インスタンスに変換します。同様に、\code{Graph.ToGraphDef}を呼び出して\code{Graph}インスタンスを等価な\code{GraphDef}インスタンスに変換することができます。

\code{GraphDef}は\ascii{protobuf}形式で存在するグラフ構造で、グラフのすべてのメタデータを含んでいます。一方、\code{Graph}はランタイムシステムでグラフ構造を記述するためのドメインオブジェクトで、\code{GraphDef}のメタデータを保持するだけでなく、グラフ構造の他の情報も含んでいます。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/local-graph-def-to-graph.png}
\caption{\code{GraphDef}と\code{Graph}間の形式変換}
 \label{fig:local-graph-def-to-graph}
\end{figure}

\subsubsection{OP配置：SimplePlacer}

\ascii{OP}の配置(\ascii{placement})とは、計算グラフに含まれる\ascii{OP}を最も効率的な方法で適切な計算デバイス上に配置し、計算リソースの利用率を最大化することを指します。これは\refig{local-cost-model}のように形式化して記述できます。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/local-cost-model.png}
\caption{コストモデル}
 \label{fig:local-cost-model}
\end{figure}

最適な配置計画を求めるのは、私の推測では\ascii{NP}問題です。この問題は計算グラフの特性、ネットワークトポロジーと帯域幅、サンプル数など多くの複雑な要因に依存し、コミュニティで最もアクティブな問題の1つでもあります。

\subsection{反復実行}

\code{DirectSession.Run}は\tf{}ランタイムの重要なパスであり、1回の反復計算を完了する責任があります。まず、\code{DirectSession}は入力/出力に基づいて\code{FullGraph}に剪定を実施し、\code{ClientGraph}を生成します。次に、保持しているローカルデバイスセットに基づいて、\code{ClientGraph}を複数の\code{PartitionGraph}に分割します。ランタイムは各\code{PartitionGraph}に対して\code{Executor}インスタンスを起動し、後者は\code{PartitionGraph}のトポロジカルソートアルゴリズムを実行して、計算グラフの実行を完了します。

具体的な実装については、\refsec{graph-operation-prune}、\refsec{graph-operation-split}、\refsec{graph-operation-exec}を参照してください。

\subsubsection{グラフ操作}

\refig{local-graph-transformation}に示すように、ローカルモードでは計算グラフは3つの形態の変換を経て、最終的に各計算デバイスに分解され、各計算デバイス上でサブグラフを並列実行できるようになります。

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/local-graph-transformation.png}
\caption{グラフ変換}
 \label{fig:local-graph-transformation}
\end{figure}

\begin{itemize}
  \item \code{FullGraph}: \ascii{Client}が構築する完全な計算グラフで、\code{FullGraph}と呼ばれます。ただし、1回の\code{Session.run}で全体の計算グラフが実行されるわけではありません。
  \item \code{ClientGraph}: \ascii{Master}が\code{Session.run}で渡される\code{feeds, fetches}入出力リストに基づいて\ascii{FullGraph}に剪定操作を実施し、ローカル反復実行の最小依存サブグラフを計算したもので、\code{ClientGraph}と呼ばれます。
  \item \code{PartitionGraph}: \ascii{Master}が現在の計算デバイスセットと\ascii{OP}のデバイス制約仕様に基づいて、\code{ClientGraph}を複数の\code{PartitionGraph}に分割します。各計算デバイスに1つの\code{PartitionGraph}が対応し、計算デバイスが\code{PartitionGraph}の実行を担当します。
\end{itemize}

ただし、\code{FullGraph, ClientGraph, PartitionGraph}のデータ構造は同じであり、これらはすべて\code{Graph}の3つの異なる表現形式で、サイズと範囲のみが異なります。

\subsubsection{形式化}

実際のシステム実装では、ローカルモードのランタイムは\ascii{C++}で実装されています。\tf{}ランタイムの重要なパスは\code{run\_step}です。実際のシステム実装には多くの詳細が含まれているため、アルゴリズムの主幹と論理を見出すのが困難です。問題の記述を簡略化するために、\code{run\_step}の実装プロセスを形式的に記述します。

\begin{leftbar}
\begin{python}
def do_run_partitions(executors_and_partitions):
  barrier = ExecutorBarrier(executors_and_partitions.size())
  for (executor, partition) in executors_and_partitions:
    executor.run(partition, barrier)  
  barrier.wait()

def run_partitions(executors_and_partitions, inputs, outputs):
  frame = FunctionCallFrame()
  frame.set_args(inputs)
  do_run_partitions(executors_and_partitions)
  frame.get_ret_vals(outputs)

def run_step(devices, full_graph, inputs, outputs):
  client_graph = prune(full_graph, inputs, outputs)
  executors_and_partitions = split(client_graph, devices)
  run_partitions(executors_and_partitions, inputs, outputs)
\end{python}
\end{leftbar}

各計算デバイス上で、\code{Executor}を起動して割り当てられた\code{PartitionGraph}を実行します。ある計算デバイスが割り当てられた\code{PartitionGraph}の実行を完了すると、\code{ExecutorBarrier}のカウンターが1増加し（初期値は\code{num\_executors}）、すべてのデバイスが\code{PartitionGraph}リストの実行を完了するまで、\code{barrier.wait()}のブロック操作が終了します。

デバイスを跨ぐ\code{PartitionGraph}間にはデータ依存関係が存在する可能性があり、それらの間では\code{Send/Recv}ノードを挿入して相互作用を完了します。実際には、ローカルモードでは、\code{Send/Recv}は\code{Rendezvous}を通じてデータ交換を完了します。\code{Send}はデータを\code{Rendezvous}に置き、\code{Recv}は識別子に基づいて\code{Rendezvous}からデータを取り出します。\code{Send}はブロックしませんが、\code{Recv}はデータが到着していない場合にブロックし、タイムアウトまで待機します。

\subsection{セッションの終了}

\begin{leftbar}
\begin{c++}
Status DirectSession::Close() {
  cancellation_manager_->StartCancel();
  {
    mutex_lock l(closed_lock_);
    if (closed_) return Status::OK();
    closed_ = true;
  }
  return Status::OK();
}
\end{c++}
\end{leftbar}

\refig{local-cancellation-manager}に示すように、\ascii{Step}を\code{DirectSession}の\code{CancellationManager}に登録します。\code{DirectSession}が閉じられると、\code{DirectSession}の\code{CancellationManager}がこの\ascii{step}の実行プロセスをキャンセルします。

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/local-cancellation-manager.png}
\caption{CancellationManagerの動作原理}
 \label{fig:local-cancellation-manager}
\end{figure}

\begin{leftbar}
\begin{c++}
Status DirectSession::Run(
   const NamedTensorList& inputs,
   const std::vector<string>& output_names,
   const std::vector<string>& target_nodes,
   std::vector<Tensor>* outputs) {
  // step\_cancellation\_manager is passed to `OpKernelContext`
  CancellationManager step_cancellation_manager;

  // Register this step with session's cancellation manager, so that
  // `Session::Close()` will cancel the step.
  CancellationToken cancellation_token =
      cancellation_manager_->get_cancellation_token();
  bool already_cancelled = !cancellation_manager_->RegisterCallback(
      cancellation_token, [&step_cancellation_manager]() {
        step_cancellation_manager.StartCancel();
      });
  // ignore others...
}
\end{c++}
\end{leftbar}

現在の\ascii{Step}の\code{CancellationManager}は最終的に\code{OpKernelContext}に渡されます。\ascii{Kernel}が計算を実装する際に中間状態を保存している場合、それに対応するコールバックフックを登録できます。各コールバックフックには一意の\code{token}識別子があります。

\ascii{Step}がキャンセルされると、コールバックフックが呼び出され、その\ascii{Kernel}はその\ascii{OP}の計算をキャンセルできます。例えば、\code{FIFOQueue}が\code{TryEnqueue}を実装する際に、この\ascii{Step}の\code{CancellationManager}にコールバックフックを登録し、その\ascii{Kernel}の中間状態情報をキャンセルするために使用します。

\begin{leftbar}
\begin{c++}
void FIFOQueue::TryEnqueue(const Tuple& tuple, OpKernelContext* ctx,
                           DoneCallback callback) {
  CancellationManager* cm = ctx->cancellation_manager();
  CancellationToken token = cm->get_cancellation_token();
  bool already_cancelled;
  {
    mutex_lock l(mu_);
    already_cancelled = !cm->RegisterCallback(
        token, [this, cm, token]() { Cancel(kEnqueue, cm, token); });
  }
  // ignore others...
}
\end{c++}
\end{leftbar}

\section{剪定}
\label{sec:graph-operation-prune}

\code{DirectSession::Run}の実行時、まず\code{ClientGraph}の構築を完了します。実際、\code{ClientGraph}の構築プロセスは、主に\code{FullGraph}の剪定アルゴリズムを完了し、\code{ClientGraph}を生成します。

\subsection{ClientGraphの構築}

\refig{local-simple-graph-execution-state}に示すように、\code{SimpleGraphExecutionState}インスタンスは\code{FullGraph}インスタンスを保持し、入力/出力リストに基づいて\code{ClientGraph}を生成します。

\begin{figure}[H]
\centering
\includegraphics[width=0.55\textwidth]{figures/local-simple-graph-execution-state.png}
\caption{\code{ClientGraph}の生成}
 \label{fig:local-simple-graph-execution-state}
\end{figure}

\code{BuildGraphOptions}には入力/出力リストが含まれており、\code{SimpleGraphExecutionState::BuildGraph}を呼び出して\code{ClientGraph}インスタンスを生成します。

\begin{leftbar}
\begin{c++}
namespace {
  BuildGraphOptions build_graph_options(
    const NamedTensorList& inputs,
    const std::vector<string>& outputs,
    const std::vector<string>& targets) {
    // sort inputs/outputs/targets
    std::vector<string> inputs_sorted(inputs.begin(), inputs.end());
    std::sort(inputs_sorted.begin(), inputs_sorted.end());

    std::vector<string> outputs_sorted(outputs.begin(), outputs.end());
    std::sort(outputs_sorted.begin(), outputs_sorted.end());

    std::vector<string> tn_sorted(targets.begin(), targets.end());
    std::sort(tn_sorted.begin(), tn_sorted.end());

    // build graph options
    BuildGraphOptions options;
    options.feed_endpoints = inputs_sorted;
    options.fetch_endpoints = outputs_sorted;
    options.target_nodes = tn_sorted;
    options.use_function_convention = !run_state_args->is_partial_run;
    return options;
  }
}

Status DirectSession::Run(
  const RunOptions& run_options,
  const NamedTensorList& inputs,
  const std::vector<string>& output_names,
  const std::vector<string>& target_nodes,
  std::vector<Tensor>* outputs,
  RunMetadata* run_metadata) {

  // 1. prune graph
  // client\_graph = prune(full\_graph, inputs, outputs)
  std::unique_ptr<SimpleClientGraph> client_graph;
  execution_state_->BuildGraph(
    build_graph_options(inputs, output_names, target_nodes), 
    &client_graph);
   
  // 2. split graph into partition by devices 
  // executors\_and\_partitions = split(client\_graph, devices)
  
  // 3. lauch executor per partition
  // def run\_partitions(executors\_and\_partitions, inputs, outputs):
  // \ \ frame = FunctionCallFrame()
  // \ \ frame.set\_args(inputs)
  // \ \ for (executor, partition) in executors\_and\_partitions: 
  // \ \ \ \ exec.run(part)
  // \ \ frame.get\_ret\_vals(outputs)

  return Status::OK();
}
\end{c++}
\end{leftbar}

\code{ClientGraph}は最初は元の\code{FullGraph}から来ており、\code{RewriteGraphForExecution}関数を呼び出して、入力/出力に基づいて\code{ClientGraph}を書き換え操作を実施し、ノードの追加や削除を行い、最終的に\code{SimpleClientGraph}インスタンスを生成します。

\begin{leftbar}
\begin{c++}
const DeviceAttributes& 
SimpleGraphExecutionState::local_device_attr() const {
  return device_set_->client_device()->attributes();
}

Status SimpleGraphExecutionState::BuildGraph(
  const BuildGraphOptions& options, 
  std::unique_ptr<SimpleClientGraph>* out) {
  // 1. create new\_graph from origin graph, 
  // which is client graph.
  std::unique_ptr<Graph> ng;
  ng.reset(new Graph(flib_def_.get()));
  CopyGraph(*graph_, ng.get());

  // 2. prune the client graph
  subgraph::RewriteGraphForExecution(
    ng.get(), options.feed_endpoints, options.fetch_endpoints,
    options.target_nodes, local_device_attr(),
    options.use_function_convention);
  }

  // 3. create SimpleClientGraph, and return it.
  std::unique_ptr<SimpleClientGraph> dense_copy(
      new SimpleClientGraph(std::move(flib)));
  CopyGraph(*ng, &dense_copy->graph);
  *out = std::move(dense_copy);

  return Status::OK();
}
\end{c++}
\end{leftbar}

したがって、\code{ClientGraph}の構築プロセスの重要なパスは\code{RewriteGraphForExecution}、つまり剪定アルゴリズムです。剪定アルゴリズムは入力/出力リストに基づいて\ascii{FullGraph}を逆方向にトラバースし、最小の依存サブグラフ\code{ClientGraph}を見つけます。

一般的に、\code{ClientGraph}の入力ノードは開始ノードの役割を果たし、出力ノードは終了ノードの役割を果たします。したがって、入力と出力に関しては2つの厄介な問題があります：

\begin{enum}
  \eitem{入力：\code{ClientGraph}の計算が開始される前に、外部のランタイムがどのように入力ノードに\code{Tensor}を渡すか}
  \eitem{出力：\code{ClientGraph}の計算が完了した後、外部のランタイムがどのように出力ノードから\code{Tensor}を取得するか}
\end{enum}

2つの媒体があります：\code{FunctionCallFrame}と\code{Rendezvous}。外部ランタイムと入力/出力ノードはこれらのいずれかの媒体を使用してデータを交換できます。

\code{FunctionCallFrame}は\code{Arg/RetVal}関数呼び出しの\ascii{OP}に使用され、関数呼び出し時に関数パラメータ値を渡し、関数値を返すために使用されます。ただし、これらは単一プロセスのランタイム環境にのみ適用されます。

\code{Rendezvous}は\code{Send/Recv}メッセージ送信の\ascii{OP}に使用され、これはより一般的な通信方法で、分散ランタイム環境に適用されます。

\subsection{Rendezvousベース}

\refig{client-prune-graph}に示すように、\code{fetches}リストに基づいて、依存するノードを逆方向に検索し、\code{feeds}に到達するまで、最小依存のサブグラフを計算します。

\code{Feed}のエッジに対して剪定を実施します。例えば、\code{ina:0}エッジを剪定し、ここに\code{Recv}ノードを挿入し、入力エッジの名前に基づいてそのノードに名前を付けます。例えば\code{\_recv\_ina\_0}のようになります。

同様に、\code{Fetch}のエッジに対しても剪定を実施します。例えば、\code{f:0}エッジを剪定し、ここに\code{Send}ノードを挿入し、出力エッジの名前に基づいてそのノードに名前を付けます。例えば\code{\_send\_f\_0}のようになります。

最終的に、\code{Source/Sink}ノードを挿入することで、剪定後に得られた各連結サブグラフを集約し、完全な\ascii{DAG}グラフを形成します。

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/client-prune-graph.png}
\caption{グラフ剪定：Send/Recvノードの挿入}
 \label{fig:client-prune-graph}
\end{figure}

\subsection{FunctionCallFrameベース}

しかし、入力/出力を\code{Rendezvous}を通じてデータ交換するとパフォーマンスのボトルネックが存在する可能性があります。送信する\code{Tensor}は送信デバイス、受信デバイス、\code{TensorId}を含む一意の文字列識別子を携帯する必要があり、データの送受信には長い文字列解析の時間オーバーヘッドがかかります。

特に、ローカルモードでは、同じプロセス内にあるため、\code{Rendezvous}を使用してデータを交換すると不要なパフォーマンスの損失が生じます。\code{FunctionCallFrame}関数呼び出しを使用して代替することができます。

したがって、ローカルモードでは、\code{Arg/RetVal}を使用して\code{Send/Recv}ノードをそれぞれ置き換えることで、関数呼び出しによるデータ交換方式を実現し、元の\code{Rendezvous}ベースのデータ交換方式を置き換えることができます。

\refig{client-prune-graph-function-ops}に示すように、\code{Feed}のエッジに対して剪定を実施します。例えば、\code{ina:0}エッジを剪定し、ここに\code{Arg}ノードを挿入し、入力エッジの名前に基づいてそのノードに名前を付けます。例えば\code{\_arg\_ina\_0}のようになります。

同様に、\code{Fetch}のエッジに対しても剪定を実施します。例えば、\code{f:0}エッジを剪定し、ここに\code{RetVal}ノードを挿入し、出力エッジの名前に基づいてそのノードに名前を付けます。例えば\code{\_retval\_f\_0}のようになります。

最終的に、\code{Source/Sink}ノードを挿入することで、剪定後に得られた各連結サブグラフを集約し、完全な\ascii{DAG}グラフを形成します。

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/client-prune-graph-function-ops.png}
\caption{グラフ剪定：Arg/RetValノードの挿入}
 \label{fig:client-prune-graph-function-ops}
\end{figure}

\subsection{剪定アルゴリズムの実装}

剪定アルゴリズムは主に\code{RewriteGraphForExecution}によって完了し、主に3つのサブプロセスを含みます。

\begin{enum}
  \eitem{入力ノードの追加}
  \eitem{出力ノードの追加} 
  \eitem{逆方向剪定}
\end{enum}

\begin{leftbar}
\begin{c++}
void RewriteGraphForExecution(Graph* g, bool use_function, 
    const ArraySlice<string>& fed_outputs,
    const ArraySlice<string>& fetch_outputs,
    const ArraySlice<string>& target_node_names,
    const DeviceAttributes& device_info) {
  FeedInputs(g, use_function, device_info, fed_outputs);

  std::vector<Node*> fetch_nodes;
  FetchOutputs(g, use_function, device_info, 
    fetch_outputs, &fetch_nodes);

  PruneForTargets(g, fetch_nodes, target_node_names);
}
\end{c++}
\end{leftbar}

\subsubsection{入力ノードの追加}

\refig{local-prune-feed}に示すように、任意の入力エッジに対して剪定を実施する際、対応する\code{Arg}または\code{Recv}ノードを挿入し、既存のエッジを削除し、関連するエッジを再接続します。

計算グラフでは、1つのエッジは\code{TensorId}によって一意に識別されます。これは\code{op:src\_output}の2項組で構成されます。前者はエッジの上流ノードを表し、後者はこのエッジが上流ノードの何番目のエッジであるかを表します。

サンプルコードでは重要でない論理の一部を削除し、一部の関数の責任を移動し、局所的に一部の関数抽出を試みて、アルゴリズムの論理をより良く再現しています。ここでは、\code{Graph}が\code{TensorId}に基づいてノードとエッジをインデックス化できると仮定しています。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/local-prune-feed.png}
\caption{剪定：入力エッジ}
 \label{fig:local-prune-feed}
\end{figure}

\begin{leftbar}
\begin{c++}
namespace {
  DataType data_type(Graph& g, const TensorId& tensor_id) {
    Node* upstream_node = g.upstream_node(tensor_id);
    return BaseType(upstream_node->output_type(tensor_id.src_output()));
  }

  Node* AppendRecvNode(Graph& g, 
    const TensorId& tensor_id, const DeviceAttributes& device_info) {
      Node* recv_node;
      NodeBuilder(strings::StrCat(
        "_recv_", tensor_id.op(), "_", tensor_id.src_output()), "_Recv")
        .Attr("tensor_type", data_type(g, tensor_id))
        .Attr("tensor_name", tensor_id.name())
        .Attr("send_device", device_info.name())
        .Attr("recv_device", device_info.name())
        .Attr("send_device_incarnation", device_info.incarnation())
        .Attr("client_terminated", true)
        .Finalize(g, &recv_node);
      return recv_node;
  }

  Node* AppendArgNode(Graph& g, size_t index, 
    const TensorId& tensor_id, const DeviceAttributes& device_info) {
    Node* arg_node;
    NodeBuilder(strings::StrCat(
      "_arg_", tensor_id.op(), "_", tensor_id.src_output()), "_Arg")
      .Attr("T", data_type(g, tensor_id))
      .Attr("index", index)
      .Finalize(g, &arg_node);
    return arg_node;
  }

  // 1. append arg/recv node
  Node* AppendNewNode(Graph& g, bool use_function, size_t index, 
    const TensorId& tensor_id∩╝îconst DeviceAttributes& device_info) {
    if (use_function) {
      return AppendArgNode(g, index, tensor_id, device_info);
    } else {
      return AppendRecvNode(g, tensor_id, device_info);
    }
  }

  void AppendNewEdges(Graph& g, 
    Node* new_node, const TensorId& tensor_id) {
    // 2. add control edge between source node and new node.
    g.AddControlEdge(g.source_node(), new_node);

    Edge* old_edge = g.edge(tensor_id);
    
    // 3. add edge between new node and downstream node.
    g.AddEdge(new_node, 0, old_edge->dst(), old_edge->dst_input());
    
    // 4. remove old edge.
    g.RemoveEdge(old_edge);
  }
}

void FeedInputs(Graph& g, bool use_function,
  const DeviceAttributes& device_info,
  const ArraySlice<TensorId>& feeds) {
  for (size_t i = 0; i < feeds.size(); ++i) {
    Node* new_node = AppendNewNode(use_function, i, feeds[i]);
    AppendNewEdges(g, new_node, feeds[i]);
  }
}
\end{c++}
\end{leftbar}

\subsubsection{出力ノードの追加}

任意の出力エッジに対して剪定を実施する際、対応する\code{RetVal}または\code{Send}ノードを挿入し、それを\code{Sink}ノードと制御依存エッジで接続します。

\refig{local-prune-fetch}に示すように、出力エッジに対して剪定操作を実施します。新しいノードと上流ノードの接続関係は、新しいノードの構築時に\code{Input}によって既に指定されています。また、関数は新しいノード（\code{RetVal/Send}）を終了ノードとして直接返すため、元のエッジを削除する必要がなく、そのアルゴリズムは入力エッジの処理と微妙な違いがあります。

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{figures/local-prune-feed.png}
  \caption{剪定：出力エッジ}
  \label{fig:local-prune-fetch}
\end{figure}

\begin{leftbar}
\begin{c++}
namespace {
  Node* AppendSendNode(Graph& g, 
    const TensorId& tensor_id, const DeviceAttributes& device_info) {
    Node* send_node;
    NodeBuilder(strings::StrCat(
      "_send_", tensor_id.op(), "_", id.src_output()), "_Send")
      // 2. add edge between upstream node and send node.
      .Input(g.upstream_node(tensor_id), tensor_id.src_output())
      .Attr("tensor_name", tensor_id.name())
      .Attr("send_device", device_info.name())
      .Attr("recv_device", device_info.name())
      .Attr("send_device_incarnation",
            device_info.incarnation())
      .Attr("client_terminated", true)
      .Finalize(g, &send_node);
    return send_node;
  }

  Node* AppendRetvalNode(Graph& g, size_t index, 
    const TensorId& tensor_id, const DeviceAttributes& device_info) {
    Node* retval_node;
    NodeBuilder(strings::StrCat(
      "_retval_", tensor_id.op(), "_", tensor_id.src_output(), "_", index), 
      "_Retval")
      // 2. add edge between upstream node and retval node.
      .Input(g.upstream_node(tensor_id), tensor_id.src_output())
      .Attr("T", data_type(g, tensor_id))
      .Attr("index", index)
      .Finalize(g, &retval_node))
    return retval_node;
  }

  // 1. append retval/send node
  Node* AppendNewNode(Graph& g, bool use_function, size_t index, 
    const TensorId& tensor_id∩╝îconst DeviceAttributes& device_info) {
    if (use_function) {
      return AppendRetvalNode(g, index, tensor_id, device_info);
    } else {
      return AppendSendNode(g, tensor_id, device_info);
    }
  }
}

void FetchOutputs(Graph& g, bool use_function,
  const DeviceAttributes& device_info,
  const ArraySlice<TensorId>& fetches,
  std::vector<Node*>& fetch_nodes) {
  for (size_t i = 0; i < fetches.size(); ++i) {
    Node* new_node = AppendNewNode(use_function, i, fetches[i]);
    
    // 3. add control edge between new node and sink node. 
    g->AddControlEdge(new_node, g->sink_node());

    fetch_nodes.push_back(new_node);
  }
}
\end{c++}
\end{leftbar}

\subsubsection{逆方向剪定}

剪定操作の本質は、\ascii{DAG}の逆方向幅優先探索アルゴリズムです。まず、キューと\code{visited}配列を作成します。後者は既に探索されたノードを記録するために使用されます。初期化時、キューには出力ノードと入力ノード（\code{targets}）のみが含まれます。グラフの探索が完了した後、\code{visited}に含まれていないノードは、今回の実行に依存していないことを示し、そのノードと関連するエッジをグラフから削除する必要があります。

剪定後、複数の\ascii{DAG}サブグラフが形成されます。入次数が\code{0}のノードを\code{Source}ノードと制御依存エッジで接続し、出次数が\code{0}のノードを\code{Sink}ノードと制御依存エッジで接続し、最終的に完全な\ascii{DAG}グラフを形成します。

\begin{leftbar}
\begin{c++}
namespace {
  void ReverseBFS(
    Graph* g, std::unordered_set<const Node*>& visited) {
    std::deque<const Node*> queue(visited.begin(), visited.end());
    while (!queue.empty()) {
      const Node* n = queue.front();
      queue.pop_front();
      for (const Node* in : n->in_nodes()) {
        if (visited.insert(in).second) {
          queue.push_back(in);
        }
      }
    }
  }

  void RemoveUnvisitedNodes(
    Graph* g, std::unordered_set<const Node*>& visited) {
    for (Node* n : g->nodes()) {
      if (visited.count(n) == 0 && !n->IsSource() && !n->IsSink()) {
        g->RemoveNode(n);
      }
    }
  }

  void PruneForReverseReachability(
    Graph* g, std::unordered_set<const Node*>& visited) {
    ReverseBFS(g, visited);
    RemoveUnvisitedNodes(g, visited);
  }

  void FixupSourceEdges(Graph* g, Node* n) {
    if (!n->IsSource() && n->in_edges().empty()) {
      g->AddControlEdge(g->source_node(), n);
    }  
  }

  void FixupSinkEdges(Graph* g, Node* n) {
    if (!n->IsSink() && n->out_edges().empty()) {
      g->AddControlEdge(n, g->sink_node());
    }  
  }

  void FixupSourceAndSinkEdges(Graph* g) {
    for (Node* n : g->nodes()) {
      FixupSourceEdges(g, n);
      FixupSinkEdges(g, n);
    }
  }

  void AppendTargetNodes(Graph& g, 
    const ArraySlice<string>& target_names,
    std::unordered_set<const Node*>& targets) {
    for (auto name : target_names) {
      Node* target = g.GetNodeBy(name);
      targets.insert(target);
    }
  }  
}

void PruneForTargets(Graph* g, 
  std::vector<Node*>& fetch_nodes,
  const ArraySlice<string>& target_names) {
  std::unordered_set<const Node*> targets(
    begin(fetch_nodes), end(fetch_nodes));

  AppendTargetNodes(g, target_names, targets);
  PruneForReverseReachability(g, targets);
  FixupSourceAndSinkEdges(g);
}
\end{c++}
\end{leftbar}

\section{分割}
\label{sec:graph-operation-split}

\refig{local-graph-split-by-device}に示すように、\code{d}ノードが\ascii{GPU0}上で実行され、他のノードが\ascii{CPU0}上で実行されると仮定します。ここで、ノード\code{a}と\code{b}は\code{Arg}を通じてデータを入力し、ノード\code{f}はその結果を\code{RetVal}ノードに出力します。

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/local-graph-split-by-device.png}
\caption{ローカルデバイスセットによるグラフ分割の実行}
 \label{fig:local-graph-split-by-device}
\end{figure}

したがって、計算グラフにはデバイスを跨ぐエッジが複数存在します。デバイスを跨ぐエッジに対して、ランタイムはそれを分割し、その場所に\code{Send/Recv}エッジを挿入します。これらは元のデバイスでデータを送信し、目標デバイスでデータを受信するためのもので、デバイス間のデータ交換を完了します。\refig{local-graph-split-insert-send-recv}に示すとおりです。

\code{Arg/RetVal}ノードは\code{FunctionCallFrame}媒体を通じてデータを交換し、\code{Send/Recv}ノードは\code{Rendezvous}媒体を通じてデータを交換します。

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/local-graph-split-insert-send-recv.png}
\caption{デバイスを跨ぐOP間にSend/Recvノードを挿入}
 \label{fig:local-graph-split-insert-send-recv}
\end{figure}

\subsection{ケース1}

最も単純なケースでは、\code{src}と\code{dst}が同じ\code{Partition}内にあります。したがって、それらを同じ\code{Partition}に直接割り当てるだけで十分です。

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{figures/split-graph-1.png}
\caption{ケース1：srcとdstが同じPartition内}
 \label{fig:split-graph-1}
\end{figure}

\subsection{ケース2}

\code{src}と\code{dst}が同じ\code{Partition}内にない場合、ただし両者の間が元々通常のエッジで接続されている場合。この場合、それらの間に\code{Send}と\code{Recv}ノードを追加し、2つの異なる\code{Partition}に割り当てるだけで十分です。

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{figures/split-graph-2.png}
\caption{ケース2：srcとdstが同じPartition内にないが、両者の間が通常のエッジ}
 \label{fig:split-graph-2}
\end{figure}

\subsection{ケース3}

\code{src}と\code{dst}が同じ\code{Partition}内にない場合、ただし両者の間が元々制御依存エッジで接続されている場合。

この場合、\code{src}側に\code{Const}の\code{DummyNode}を追加し、それを\code{src}の下流として制御依存エッジで接続する必要があります。最終的に、\code{Send}を通じてその値を対向側に送信します。

\code{dst}側では、\code{Recv}がその値を受信し、\code{Identity}を使用してそれを消費します。最後に、\code{Identity}と\code{dst}を制御依存エッジで接続します。

ここで、\code{Const}は生産者の役割を果たし、\code{Identity}は消費者の役割を果たします。これにより、デバイス間通信の要求を満たすと同時に、元の\code{src}と\code{dst}間の制御依存関係も満たします。ただし、欠点としてわずかなパフォーマンスオーバーヘッドが存在します。

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/split-graph-3.png}
\caption{ケース3：srcとdstが同じPartition内にないが、両者の間が制御依存エッジ}
 \label{fig:split-graph-3}
\end{figure}

\subsection{分割アルゴリズムの実装}

分割アルゴリズムも、グラフの逆方向探索アルゴリズムです。現在探索中のノードを\code{dst}としてマークし、次に\code{dst}のすべての入力エッジを探します。すべての入力エッジを探索し、そのエッジに接続されているソースノードを見つけ、それを\code{src}としてマークします。

したがって、上記で議論した3つのケースに基づいて、\code{src}と\code{dst}間の\code{Partition}分割アルゴリズムを反復的に実装します。

\begin{leftbar}
\begin{c++}
namespace {
  
  using Edges = std::vector<const Edge*>;
  using Partitions = std::unordered_map<string, GraphDef>;

  void AddInput(NodeDef* dst, StringPiece src_name, int src_slot) {
    if (src_slot == Graph::kControlSlot) {
      dst->add_input(strings::StrCat("^", src_name));
    } else if (src_slot == 0) {
      dst->add_input(src_name.data(), src_name.size());
    } else {
      dst->add_input(strings::StrCat(src_name, ":", src_slot));
    }
  }

  Edges InputsOf(const Node* dst) {
    Edges inputs(dst->num_inputs(), nullptr);
    for (auto edge : dst.in_edges()) {
      if (edge->IsControlEdge()) {
        inputs.push_back(e);
      } else {
        inputs[edge->dst_input()] = edge;
      }
    }
    return inputs;
  }

  NodeDef* InitDstNodeDef(const Node& dst, NodeDef* dst_def) {
    dst_def = dst.def();
    dst_def->set_device(dst.assigned_device_name());
    dst_def->clear_input();
    return dst_def;  
  }

  NodeDef* AddDummyConst(const PartitionOptions& opts, GraphDef* gdef,
                         const Edge* edge, Status* status) {
    const Node* src = edge->src();
    Tensor tensor(DT_FLOAT, TensorShape({0}));
    NodeDef* result = gdef->add_node();
    *status = NodeDefBuilder(opts.new_name(src->name()), "Const")
                  .Device(src->assigned_device_name())
                  .Attr("dtype", DT_FLOAT)
                  .Attr("value", tensor)
                  .Finalize(result);
    return result;
  }

  NodeDefBuilder::NodeOut BuildSendFrom(
      const PartitionOptions& opts,
      GraphDef* src_graph,
      const Edge* edge,
      NodeDefBuilder::NodeOut& send_from) {
    if (edge->IsControlEdge()) {
      // Case 3: DummyNode(Const) -ctrl-> src -> send  
      NodeDef* dummy = AddDummyConst(opts, src_graph, edge);
      AddInput(dummy, edge->src()->name(), Graph::kControlSlot);
      send_from.Reset(dummy->name(), 0, DT_FLOAT);
    } else {
      // Case 2: src -> send  
      send_from.Reset(edge->src()->name(),
                      edge->src_output(), 
                      EdgeType(edge));
    }
  }

  void SetSendRecvAttrs(
      const PartitionOptions& opts, 
      const Edge* edge,
      NodeDefBuilder* builder) {
    builder->Attr("tensor_name",
                  strings::StrCat("edge_", edge->id(), "_", edge->src()->name()));
    builder->Attr("send_device", edge->src()->assigned_device_name());
    builder->Attr("send_device_incarnation",
                  static_cast<int64>(
                      opts.get_incarnation(edge->src()->assigned_device_name())));
    builder->Attr("recv_device", edge->dst()->assigned_device_name());
    builder->Attr("client_terminated", false);
  }

  NodeDef* AddSend(
      const PartitionOptions& opts, 
      GraphDef* gdef, 
      const Edge* edge,
      NodeDefBuilder::NodeOut send_from) {
    NodeDef* send = gdef->add_node();
    NodeDefBuilder builder(opts.new_name(edge->src()->name()), "_Send");
    SetSendRecvAttrs(opts, edge, &builder);
    builder.Device(edge->src()->assigned_device_name())
           .Input(send_from)
           .Finalize(send);
    return send;
  }

  NodeDef* AddRecv(const PartitionOptions& opts, const GraphInfo& g_info,
                   GraphDef* gdef, const Edge* edge, NodeDef** real_recv,
                   Status* status) {
    NodeDef* recv = gdef->add_node();
    NodeDefBuilder builder(opts.new_name(src->name()), "_Recv");
    SetSendRecvAttrs(opts, edge, &builder);
    builder.Device(dst->assigned_device_name())
           .Attr("tensor_type", EdgeType(edge))
           .Finalize(recv);
    return recv;

    if (edge->IsControlEdge()) {
      // Case 3: Recv -> Identity -contrl-> dst
      NodeDef* id = gdef->add_node();
      NodeDefBuilder(opts.new_name(src->name()), "Identity")
          .Device(dst->assigned_device_name())
          .Input(recv->name(), 0, cast_dtype)
          .Finalize(id);
      return id;
    } else {
      return recv;
    }
  }

  void InsertSendRecv(
      const PartitionOptions& opts,
      GraphDef* src_graph, 
      Edge* edge, 
      GraphDef* dst_graph, 
      NodeDef* dst_def) {
    NodeDefBuilder::NodeOut send_from;
    BuildSendFrom(opts, src_graph, edge, send_from);

    NodeDef* send = AddSend(opts, src_graph, edge, send_from);
    NodeDef* recv = AddRecv(opts, dst_graph, edge);

    if (edge->IsControlEdge()) {
      // Case 3: In fact, recv is identity.
      AddInput(dst_def, recv->name(), Graph::kControlSlot);
    } else {
      AddInput(dst_def, recv->name(), 0);
    }
  }
}

Status Partition(const PartitionOptions& opts, 
                 Partitions& partitions, Graph& client_graph) {
  for (const Node* dst : client_graph.op_nodes()) {
    // 1. find dst node
    GraphDef* dst_graph = &partitions[opts.node_to_loc(dst)];
    NodeDef* dst_def = InitDstNodeDef(*dst, dst_graph->add_node());
    
    // 2. search all input edges.
    for (const Edge* edge : InputsOf(dst)) {
      // 3. find src node: edge->src()
      GraphDef* src_graph = &partitions[opts.node_to_loc(src)];

      // skip sink/source nodes.
      if (!edge->src()->IsOp()) 
        continue;  

      // Case 1: same partition
      if (src_graph == dst_graph) {
        AddInput(dst_def, src->name(), edge->src_output());
        continue;
      }

      // Case 2-3: different partition
      InsertSendRecv(opts, src_graph, edge, dst_graph, dst_def);
    }
  }
}
\end{c++}
\end{leftbar}

\subsection{コールバック関数}

\code{PartitionOptions}には、2つの重要なコールバック関数があります。\code{NodeToLocFunc}はグラフ分割に使用され、\code{NewNameFunc}は新しく追加されたノードに名前を付けるために使用されます（例：\code{Send/Recv}）。

\begin{leftbar}
\begin{c++}
struct PartitionOptions {
  typedef std::function<string(const Node*)> NodeToLocFunc;
  NodeToLocFunc node_to_loc = nullptr;

  typedef std::function<string(const string&)> NewNameFunc;
  NewNameFunc new_name = nullptr;

  // ignore others...
};
\end{c++}
\end{leftbar}

グラフ分割には、2つの最も基本的な分割方法があります。

\begin{leftbar}
\begin{c++}
string SplitByDevice(const Node* node) {
  return node->assigned_device_name();
}

string SplitByWorker(const Node* node) {
  string task, device;
  DeviceNameUtils::SplitDeviceName(
      node->assigned_device_name(), &task, &device);
  return task;
}
\end{c++}
\end{leftbar}

ローカルモードでは、\code{NodeToLocFunc}は\code{SplitByDevice}に設定されます。図\code{intraprocess-splity-by-device}に示すとおりです。

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{figures/intraprocess-splity-by-device.png}
\caption{ローカルモード：SplitByDevice}
 \label{fig:intraprocess-splity-by-device}
\end{figure}

分散モードでは、\code{Master}の\code{NodeToLocFunc}は\code{SplitByWorker}に設定され、\code{Worker}の\code{NodeToLocFunc}は\code{SplitByDevice}に設定されます。

したがって、分散モードでは、グラフ分割は2段階の分離を経験します。第1段階では\code{SplitByWorker}に基づいて分割し、グラフを各\code{Worker}に分割します。第2段階では\code{SplitByDevice}に基づいて、グラフを各計算デバイスに分割します。

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{figures/interprocess-splity-by-worker.png}
\caption{分散モード：2段階分割}
 \label{fig:interprocess-splity-by-worker}
\end{figure}

\section{実行}
\label{sec:graph-operation-exec}

次に、ランタイムは各\code{PartitionGraph}を並列実行します。\refig{local-graph-execution}に示すように、各\code{PartitionGraph}に対して\code{Executor}を起動し、グラフの計算を並列実行します。

各\code{Executor}は\code{PartitionGraph}のトポロジカルソートアルゴリズムを実行し、入次数が\ascii{0}の\ascii{OP}を\code{ready\_queue}に追加し、それに関連する\ascii{OP}の入次数を1減らします。スケジューラーは\code{ready\_queue}内の\ascii{OP}をスケジュールし、それを\code{ThreadPool}に入れて対応する\ascii{Kernel}実装を実行します。

すべての\code{Partition}が並列実行を開始する前に、外部がその入力を対応する\code{Arg}ノードに渡す必要があります。すべての\code{Partition}が計算を完了した後、外部は\code{RetVal}ノードからデータを取り出します。\code{Arg/RetVal}ノード間のデータは\code{FunctionCallFrame}を通じて交換されます。

\code{PartitionGraph}間でデバイスを跨いでデータを交換する必要がある場合、生産者はそれを\code{Send}ノードに置き、消費者は\code{Recv}ノードを通じてデータを取得します。送信側はブロックしませんが、受信側はデータが到着していない場合、タイムアウトまでブロックします。また、\code{Send/Recv}ノード間のデータは\code{Rendezvous}を通じて交換されます。

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/local-graph-execution.png}
\caption{グラフの実行}
 \label{fig:local-graph-execution}
\end{figure}

したがって、グラフ計算の実行には以下の3つの核心的な問題を解決する必要があります：

\begin{enum}
  \eitem{入力/出力の処理}
  \eitem{デバイス間のデータ交換} 
  \eitem{\code{PartitionGraph}の実行}
\end{enum}

\subsection{入力}

あるデバイス上で、\code{PartitionGraph}の開始ノードは\code{Arg}ノードであり、終了ノードは\code{RetVal}ノードです。このプロセス全体は関数呼び出しプロセスとみなすことができ、\code{Arg}は関数パラメータの受け渡しに使用され、\code{RetVal}は関数値の返却に使用されます。

より正確には、\code{Arg}は\code{PartitionGraph}の入力を完了し、\code{RetVal}は\code{PartitionGraph}の出力を完了します。\code{Arg}ノードの呼び出し順序は：\code{set\_arg -> get\_arg}です。前者は\code{DirectSession}が\code{Executor}リストを起動する前に、\code{FunctionCallFrame.SetArgs(feeds)}を呼び出して入力パラメータリストの値を渡します。後者は\code{Arg}の\ascii{Kernel}実装が呼び出します。

\begin{leftbar}
\begin{c++}
Status DirectSession::Run(
  const RunOptions& run_options,
  const NamedTensorList& inputs,
  const std::vector<string>& output_names,
  const std::vector<string>& target_nodes,
  std::vector<Tensor>* outputs,
  RunMetadata* run_metadata) {

  // 1. prune graph
  // client\_graph = prune(full\_graph, inputs, outputs)
   
  // 2. split graph into partition by devices 
  // executors\_and\_partitions = split(client\_graph, devices)
  ExecutorsAndKeys* executors_and_keys = ... // ignore implements...
  
  // 3. lauch executor per partition
  // def run\_partitions(executors\_and\_partitions, inputs, outputs):
  // \ \ frame = FunctionCallFrame()
  // \ \ frame.set\_args(inputs)
  // \ \ for (executor, partition) in executors\_and\_partitions: 
  // \ \ \ \ exec.run(part)
  // \ \ frame.get\_ret\_vals(outputs)

  // 3.1 construct FunctionCallFrame
  FunctionCallFrame call_frame(
    executors_and_keys->input_types,
    executors_and_keys->output_types);
  
  // 3.2 frame.set\_args(inputs)
  // 3.2.1 construct feeds list
  gtl::InlinedVector<Tensor, 4> feed_args(inputs.size());
  for (const auto& it : inputs) {
    // (first, second) => (tensor\_name, tensor)
    feed_args[executors_and_keys->input_name_to_index[it.first]] = it.second;
  }

  // 3.2.2 frame.set\_args(feeds)
  call_frame.SetArgs(feed_args);
  
  // 3.3 concurent execution
  // for (executor, partition) in executors\_and\_partitions:
  // \ \ executor.run(partition) 

  // 3.4 fetch outputs.
}
\end{c++}
\end{leftbar}

一方、\code{frame.get\_arg}は\code{Arg}によって取得され、\code{Arg}はそれを\code{PartitionGraph}内の最初の計算ノードに出力します。

\begin{leftbar}
\begin{c++}
struct ArgOp : OpKernel {
  explicit ArgOp(OpKernelConstruction* ctx) : OpKernel(ctx) {
    ctx->GetAttr("T", &dtype_);
    ctx->GetAttr("index", &index_);
  }

  void Compute(OpKernelContext* ctx) override {
    auto frame = ctx->call_frame();

    Tensor val;
    frame->GetArg(index_, &val);

    // put it into downsteram op's input.
    ctx->set_output(0, val); 
  }

 private:
  int index_;
  DataType dtype_;
};
\end{c++}
\end{leftbar}

\subsection{並列実行}

グラフ分割後、ランタイムは各\code{Partition}に対して\code{Executor}を起動します。すべての\code{Executor}が完了したかどうかを監視するために、\code{ExecutorBarrier}が作成されます。そして、すべての\code{Executor}を起動した後、\code{executors\_done.Wait()}ブロック操作を呼び出し、すべての\code{Executor}が実行を完了するのを待ちます。

1つの\code{Executor}が完了すると、\code{ExecutorBarrier}のカウンターが1減少します（初期値は\code{num\_executors}）。0になると、その完了フックが呼び出され、最終的に\code{executors\_done.Notify()}がトリガーされます。

\begin{leftbar}
\begin{c++}
Status DirectSession::Run(
  const RunOptions& run_options,
  const NamedTensorList& inputs,
  const std::vector<string>& output_names,
  const std::vector<string>& target_nodes,
  std::vector<Tensor>* outputs,
  RunMetadata* run_metadata) {

  // 1. prune graph
  // client\_graph = prune(full\_graph, inputs, outputs)
   
  // 2. split graph into partition by devices 
  // executors\_and\_partitions = split(client\_graph, devices)
  ExecutorsAndKeys* executors_and_keys = ... // ignore implements...
  
  // 3. lauch executor per partition
  // def run\_partitions(executors\_and\_partitions, inputs, outputs):
  // \ \ frame = FunctionCallFrame()
  // \ \ frame.set\_args(inputs)
  // \ \ for (executor, partition) in executors\_and\_partitions: 
  // \ \ \ \ exec.run(part)
  // \ \ frame.get\_ret\_vals(outputs)

  // 3.1 construct FunctionCallFrame
  FunctionCallFrame call_frame(
    executors_and_keys->input_types,
    executors_and_keys->output_types);
  
  // 3.2 frame.set\_args(inputs)
  // 3.2.1 construct feeds list
  gtl::InlinedVector<Tensor, 4> feed_args(inputs.size());
  for (const auto& it : inputs) {
    // (first, second) => (tensor\_name, tensor)
    feed_args[executors_and_keys->input_name_to_index[it.first]] = it.second;
  }

  // 3.2.2 frame.set\_args(feeds)
  call_frame.SetArgs(feed_args);
  
  // 3.3 concurent execution
  // barrier = ExecutorBarrier(executors\_and\_partitions.size())
  // for (executor, partition) in executors\_and\_partitions:
  // \ \ executor.run(partition) 
  // barrier.wait()
  RunState run_state(&devices_);
  run_state.rendez = new IntraProcessRendezvous(device_mgr_.get());
  
  // 3.3.1 notify when finished.
  size_t num_executors = executors_and_keys->items.size();
  ExecutorBarrier* barrier = new ExecutorBarrier(
      num_executors, run_state.rendez, [&run_state](const Status& ret) {
        {
          mutex_lock l(run_state.mu_);
          run_state.status.Update(ret);
        }
        run_state.executors_done.Notify();
      });

  Executor::Args args;
  args.call_frame = &call_frame;
  args.rendezvous = run_state.rendez;
  args.runner = [this, pool](Executor::Args::Closure c) {
    SchedClosure(pool, std::move(c));
  };

  // 3.3.2 lauch all executors.
  for (const auto& item : executors_and_keys->items) {
    item.executor->RunAsync(args, barrier->Get());
  }

  // 3.3.3 wait until all executors finished.
  WaitForNotification(&run_state, 
      &step_cancellation_manager,
      GetTimeoutInMs(run_options));

  // 3.4 fetch outputs.
}
\end{c++}
\end{leftbar}

\subsection{出力}

同様に、\code{RetVal}ノードの呼び出し順序は：\code{set\_ret\_val -> get\_ret\_val}です。前者は\code{RetVal}によって完了し、後者は\code{DirectSession}によって完了します。

\begin{leftbar}
\begin{c++}
struct RetvalOp : OpKernel {
  explicit RetvalOp(OpKernelConstruction* ctx) : OpKernel(ctx) {
    ctx->GetAttr("T", &dtype_);
    ctx->GetAttr("index", &index_);
  }

  void Compute(OpKernelContext* ctx) override {
    // get upstream op's output.
    const Tensor& val = ctx->input(0); 

    auto frame = ctx->call_frame();
    frame->SetRetval(index_, val);
  }

 private:
  int index_;
  DataType dtype_;
};
\end{c++}
\end{leftbar}

すべての\code{Executor}の実行が終了すると、\code{DirectSession}は\code{FunctionCallFrame}からすべての出力値を取り出し、それを\code{outputs}に配置して\ascii{Client}に返すことができます。

\begin{leftbar}
\begin{c++}
Status DirectSession::Run(
  const RunOptions& run_options,
  const NamedTensorList& inputs,
  const std::vector<string>& output_names,
  const std::vector<string>& target_nodes,
  std::vector<Tensor>* outputs,
  RunMetadata* run_metadata) {
  
  // 1. prune graph
  // client\_graph = prune(full\_graph, inputs, outputs)
   
  // 2. split graph into partition by devices 
  // executors\_and\_partitions = split(client\_graph, devices)
  executors_and_keys = ... // ignore implements...
  
  // 3. lauch executor per partition
  // def run\_partitions(executors\_and\_partitions, inputs, outputs):
  // \ \ frame = FunctionCallFrame()
  // \ \ frame.set\_args(inputs)
  // \ \ for (executor, partition) in executors\_and\_partitions: 
  // \ \ \ \ exec.run(part)
  // \ \ frame.get\_ret\_vals(outputs)

  // 3.1 construct FunctionCallFrame
  FunctionCallFrame call_frame(
    executors_and_keys->input_types,
    executors_and_keys->output_types);
  
  // 3.2 frame.set\_args(inputs)
  // 3.2.1 construct feeds list
  gtl::InlinedVector<Tensor, 4> feed_args(inputs.size());
  for (const auto& it : inputs) {
    // (first, second) => (tensor\_name, tensor)
    feed_args[executors_and_keys->input_name_to_index[it.first]] = it.second;
  }

  // 3.2.2 frame.set\_args(feeds)
  call_frame.SetArgs(feed_args);
  
  // 3.3 concurent execution
  // barrier = ExecutorBarrier(executors\_and\_partitions.size())
  // for (executor, partition) in executors\_and\_partitions:
  // \ \ executor.run(partition) 
  // barrier.wait()
  RunState run_state(&devices_);
  run_state.rendez = new IntraProcessRendezvous(device_mgr_.get());
  
  // 3.3.1 notify when finished.
  size_t num_executors = executors_and_keys->items.size();
  ExecutorBarrier* barrier = new ExecutorBarrier(
      num_executors, run_state.rendez, [&run_state](const Status& ret) {
        {
          mutex_lock l(run_state.mu_);
          run_state.status.Update(ret);
        }
        run_state.executors_done.Notify();
      });

  Executor::Args args;
  args.call_frame = &call_frame;
  args.rendezvous = run_state.rendez;
  args.runner = [this, pool](Executor::Args::Closure c) {
    SchedClosure(pool, std::move(c));
  };

  // 3.3.2 lauch all executors.
  for (const auto& item : executors_and_keys->items) {
    item.executor->RunAsync(args, barrier->Get());
  }

  // 3.3.3 wait until all executors finished.
  WaitForNotification(&run_state, 
      &step_cancellation_manager,
      GetTimeoutInMs(run_options)); 

  // 3.4 fetch outputs. 
  // 3.4.1 frame.get\_get\_ret\_vals
  std::vector<Tensor> sorted_outputs;
  Status s = call_frame.ConsumeRetvals(&sorted_outputs);

  // 3.4.2 emplace to outputs, and return to client.
  outputs->reserve(sorted_outputs.size());
  for (int i = 0; i < output_names.size(); ++i) {
    const string& output_name = output_names[i];
    outputs->emplace_back(
      std::move(sorted_outputs[
        executors_and_keys->output_name_to_index[output_name]]));
  }
}
\end{c++}
\end{leftbar}

ここまでで、\code{DirectSession.Run}の解読が完了しました。しかし、\code{Partition}内のノードがどのようにスケジュールされて実行されるのか、\code{Partition}間の\code{Send/Recv}がどのように機能するのかという疑問が残ります。

したがって、最後のマイルでは、さらに3つのことを探究する必要があります。

\begin{enum}
  \eitem{\code{SendOp}と\code{RecvOp}の動作原理}
  \eitem{\code{IntraProcessRendezvous}の動作原理} 
  \eitem{\code{Executor}のスケジューリングアルゴリズム}
\end{enum}

\section{デバイス間通信}

\code{SendOp/RecvOp}は\code{Rendezvous}を通じてデータを交換します。これはメッセージの送受信を実装し、具体的なメッセージ伝達から切り離されています。例えば、単一プロセス内では、\code{SendOp/RecvOp}は\code{IntraProcessRendezvous}に基づいてデータを転送します。一方、マルチプロセス環境では、\code{SendOp/RecvOp}は\code{GrpcRendezvous}に基づいてデータを転送できます。

まず、これら2つの\ascii{OP}の動作原理を探ります。次に、ローカルモードでの\code{IntraProcessRendezvous}の動作原理を探ります。

\subsection{SendOpの実装}

\refig{local-send-recv-ops}に示すように、プロセス内の\code{Send/Recv}は一意の識別子\code{ParsedKey}を通じてデータ交換を実現します。

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/local-send-recv-ops.png}
\caption{プロセス内の\code{SendOp}と\code{RecvOp}のデータ交換}
 \label{fig:local-send-recv-ops}
\end{figure}

\code{SendOp}の\ascii{Kernel}実装を参照すると、非常に複雑に見えますが、実際には1つのことだけを行っています。まず、デバイス間通信の鍵となる\code{ParsedKey}を構築し、次に\code{Rendezvous.Send}操作を呼び出して、上流の\ascii{OP}から\code{SendOp}に入力された\code{Tensor}を\code{Rendezvous}キャッシュに送信します。この操作はノンブロッキングです。

\code{ParsedKey}は、送信デバイス、受信デバイス、デバイスのグローバル識別子、および送信する\code{Tensor}の識別子（\code{src:output\_index}）で構成されます。

\begin{leftbar}
\begin{c++}
struct SendOp : OpKernel {
  explicit SendOp(OpKernelConstruction* ctx) : OpKernel(ctx) {
    string send_device;
    ctx->GetAttr("send_device", &send_device);

    string recv_device;
    ctx->GetAttr("recv_device", &recv_device);

    uint64 send_device_incarnation;
    ctx->GetAttr(
        "send_device_incarnation",
        reinterpret_cast<int64*>(&send_device_incarnation));

    string tensor_name;
    ctx->GetAttr("tensor_name", &tensor_name);

    key_prefix_ = GetRendezvousKeyPrefix(
        send_device, recv_device,
        send_device_incarnation, tensor_name);

    GetRendezvousKey(key_prefix_, {0, 0}, &parsed_key_.buf_);
    Rendezvous::ParseKey(parsed_key_.buf_, &parsed_key_);

    if (!ctx->GetAttr("_hostmem_sendrecv", &hostmem_sendrecv_).ok()) {
      hostmem_sendrecv_ = false;
    }
  }

  void Compute(OpKernelContext* ctx) override {
    Rendezvous::Args args;
    args.device_context = ctx->op_device_context();
    args.alloc_attrs = ctx->input_alloc_attr(0);
    
    // get it from upstream op's output, and as this op's input.
    ctx->rendezvous()->Send(
        CreateParsedkey(ctx), args, ctx->input(0),
        ctx->is_input_dead());
  }
 
 private:
  Rendezvous::ParsedKey CreateParsedkey(OpKernelContext* ctx) {
    FrameAndIter frame_iter = GetFrameAndIter(ctx, hostmem_sendrecv_);
    if (frame_iter == FrameAndIter(0, 0)) {
      return parsed_key_;
    } else {
      Rendezvous::ParsedKey in_loop_parsed;
      GetRendezvousKey(key_prefix_, frame_iter, &in_loop_parsed.buf_);
      Rendezvous::ParseKey(in_loop_parsed.buf_, &in_loop_parsed);
      return in_loop_parsed;
    }  
  }

 private:
  string key_prefix_;
  Rendezvous::ParsedKey parsed_key_;
  bool hostmem_sendrecv_;
};
\end{c++}
\end{leftbar}

\subsection{RecvOpの実装}

同様に、\code{Recv}の\ascii{Kernel}の実装を推測できます。まず\code{Rendezvous}の\code{ParsedKey}を構築し、次に\code{Rendezvous.RecvAsync}操作を呼び出して、\code{Rendezvous}から対応する\code{Tensor}を取得します。

これは非同期操作で、\code{Rendezvous}内のデータが取得可能になると、コールバック関数\code{done\_cb}の実行が開始され、取得した\code{Tensor}を下流の\ascii{OP}に出力します。

\begin{leftbar}
\begin{c++}
struct RecvOp : AsyncOpKernel {
  explicit RecvOp(OpKernelConstruction* ctx) : AsyncOpKernel(ctx) {
    string send_device;
    ctx->GetAttr("send_device", &send_device);
  
    string recv_device;
    ctx->GetAttr("recv_device", &recv_device);

    uint64 send_device_incarnation;
    ctx->GetAttr(
        "send_device_incarnation",
        reinterpret_cast<int64*>(&send_device_incarnation));
  
    string tensor_name;
    ctx->GetAttr("tensor_name", &tensor_name);

    key_prefix_ = GetRendezvousKeyPrefix(
        send_device, recv_device,
        send_device_incarnation, tensor_name);
  
    GetRendezvousKey(key_prefix_, {0, 0}, &parsed_key_.buf_);
    Rendezvous::ParseKey(parsed_key_.buf_, &parsed_key_));
    if (!ctx->GetAttr("_hostmem_sendrecv", &hostmem_sendrecv_).ok()) {
      hostmem_sendrecv_ = false;
    }
  }

  void ComputeAsync(OpKernelContext* ctx, DoneCallback done) override {
    Rendezvous::Args args;
    args.device_context = ctx->op_device_context();
    args.alloc_attrs = ctx->output_alloc_attr(0);

    ctx->rendezvous()->RecvAsync(
      CreateParsedKey(ctx), args, CreateDoneCallback(ctx));
  }

 private:
  Rendezvous::ParsedKey CreateParsedKey(OpKernelContext* ctx) {
    FrameAndIter frame_iter = GetFrameAndIter(ctx, hostmem_sendrecv_);
    if (frame_iter == FrameAndIter(0, 0)) {
      return parsed_key_;
    } else {
      Rendezvous::ParsedKey in_loop_parsed;
      GetRendezvousKey(key_prefix_, frame_iter, &in_loop_parsed.buf_);
      Rendezvous::ParseKey(in_loop_parsed.buf_, &in_loop_parsed);
      return in_loop_parsed;
    }  
  }

  Rendezvous::DoneCallback CreateDoneCallback(OpKernelContext* ctx) {
    using namespace std::placeholders;
    return std::bind([ctx](DoneCallback done, const Status& s, 
        const Rendezvous::Args&, const Rendezvous::Args&, 
        const Tensor& val, bool is_dead) {
          ctx->SetStatus(s);
          if (s.ok()) {
            if (!is_dead) {
              // put it into downstream op's input.
              ctx->set_output(0, val);  
            }
            *ctx->is_output_dead() = is_dead;
          }
          done();
        },
        std::move(done), _1, _2, _3, _4, _5);  
  }

 private:
  string key_prefix_;
  Rendezvous::ParsedKey parsed_key_;
  bool hostmem_sendrecv_;
};
\end{c++}
\end{leftbar}
