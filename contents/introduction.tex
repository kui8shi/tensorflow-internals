\begin{savequote}[45mm]
\ascii{Any fool can write code that a computer can understand. Good programmers write code that humans can understand.}
\qauthor{\ascii{- Martin Flower}}
\end{savequote}

\chapter{はじめに} 
\label{ch:introduction}

\begin{content}

\tf{}は\emph{データフローグラフ}\ascii{(Dataflow Graph)}を使用して数値計算を表現するオープンソースソフトウェアライブラリです。抽象的な数学的計算を\emph{ノード}として表現し、計算ロジックを\ascii{OP}として表現します。一方、\emph{エッジ}はノード間を流れるデータフローを表し、データの表現を\ascii{Tensor}として表現します\upcite{tf-white-paper}。データフローグラフは\emph{有向非巡回グラフ}\ascii{(DAG)}の一種で、グラフ内の\ascii{OP}が特定のトポロジカル順序で実行されると、\ascii{Tensor}がグラフ内を流れてデータフローを形成し、これが\tf{}の名前の由来となっています。

分散実行時には、データフローグラフが複数のサブグラフに分割され、クラスター内の複数のマシンに効率的に展開されて並行実行されます。1台のマシン内では、登録されたサブグラフがさらに小さなサブグラフに分割され、\emph{ローカルデバイスセット}上で並行実行されます。\tf{}は\ascii{CPU、GPU、ASIC}を含む多様な異種デバイスの分散計算をサポートしています。\tf{}のクロスプラットフォーム性能により、デスクトップ、サーバー、モバイル端末など、さまざまな計算プラットフォームに柔軟に展開できます。

\tf{}は当初、\ascii{Google Brain}の研究者とエンジニアによって開発され、機械学習と深層ニューラルネットワークの研究に使用されました。これには音声認識、コンピュータビジョン、自然言語理解、ロボティクス、情報検索が含まれます。しかし、\tf{}のシステムアーキテクチャの汎用性と柔軟性により、他の科学分野の数値計算にも広く使用されるようになりました。

\end{content}

\section{過去と現在}

\begin{content}

\ascii{Google Brain}プロジェクトは\ascii{2011}年に始まり、超大規模な深層ニューラルネットワークの研究を目的としていました。プロジェクトの初期段階で、\ascii{Google Brain}は第一世代の分散深層学習フレームワークである\ascii{DistBelief}を構築し、\ascii{Google}内部の製品で広く応用されました。

\ascii{DistBelief}の経験に基づいて、\ascii{Google Brain}は深層学習のトレーニングと推論のニーズ、および深層学習フレームワークのシステム動作と特性についてより包括的で深い理解を得ました。そして\ascii{2015年11月}に第二世代の分散深層学習フレームワークである\tf{}を発表しました。\tf{}は\ascii{DistBelief}の後継者として、既存のシステムアーキテクチャを革命的に再設計・実装しました。\tf{}は発表後すぐに深層学習分野で注目を集め、コミュニティに大きな影響を与えました。

\subsection{DistBelief}

\ascii{DistBelief}は大規模ニューラルネットワークのトレーニングのための分散システムであり、\ascii{Google}の第一世代分散機械学習フレームワークです。\ascii{2011}年以来、\ascii{Google}内部で\ascii{DistBelief}を大規模に使用して大規模ニューラルネットワークをトレーニングし、機械学習と深層学習分野の研究と応用に広く使用されてきました。これには教師なし学習、言語表現、画像分類、物体検出、ビデオ分類、音声認識、シーケンス予測、歩行者検出、強化学習などが含まれます。

\subsubsection{プログラミングモデル}

\ascii{DistBelief}のプログラミングモデルは\emph{レイヤー}ベースの\ascii{DAG}グラフです。レイヤーは複数の演算子を組み合わせた複合演算子と見なすことができ、特定の計算タスクを実行します。例えば、全結合層は$f({W^T}x + b)$の複合計算を実行します。これには入力と重みの行列乗算、その後のバイアスの加算、最後に線形加重値に活性化関数を適用して非線形変換を実施することが含まれます。

\subsubsection{アーキテクチャ}

\ascii{DistBelief}は\emph{パラメータサーバー}\ascii{(Parameter Server, 通常PSと呼ばれる)}のシステムアーキテクチャを使用し、トレーニングジョブは2つの分離したプロセスを含みます：モデルのトレーニングに使用される状態を持たない\ascii{Worker}プロセスと、モデルのパラメータを維持する状態を持つ\ascii{PS}プロセスです。\refig{parameter-server}に示すように、分散トレーニングプロセスでは、各\emph{モデルレプリカ}が非同期的に\ascii{PS}からトレーニングパラメータ$w$を取得し、1ステップの反復計算が完了すると、パラメータの勾配$ \Delta w $を\ascii{PS}にプッシュしてパラメータの更新を完了します。

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/parameter-server.png}
\caption{DistBelief: パラメータサーバーアーキテクチャ}
 \label{fig:parameter-server}
\end{figure}

\subsubsection{欠点}

しかし、深層学習分野の上級ユーザーにとって、\ascii{DistBelief}のプログラミングモデルと\ascii{PS}ベースのシステムアーキテクチャは十分な柔軟性と拡張性に欠けていました。

\begin{enum}
  \eitem{最適化アルゴリズム：新しい最適化アルゴリズムを追加するには、\ascii{PS}の実装を変更する必要がありました。\code{get(), put()}の抽象メソッドは、一部の最適化アルゴリズムに対して効率的ではありませんでした。}
  \eitem{トレーニングアルゴリズム：フィードフォワード以外のニューラルネットワークのサポートは大きな課題に直面しました。例えば、ループを含む\ascii{RNN}、交互にトレーニングする敵対的ネットワーク、損失関数が分離したエージェントによって完成される強化学習モデルなどです。} 
  \eitem{アクセラレータデバイス：\ascii{DistBelief}は当初マルチコア\ascii{CPU}のみをサポートし、マルチ\ascii{GPU}をサポートしていませんでした。レガシーのシステムアーキテクチャは新しい計算デバイスをサポートするための良好な拡張性に欠けていました。}
\end{enum}

\subsection{TensorFlow}

\ascii{DistBelief}のレガシーアーキテクチャと設計は、深層学習の日々増大するニーズの変化にもはや対応できなくなりました。\ascii{Google}は既存の\ascii{DistBelief}の実装を断固として放棄し、その基礎の上に全く新しいシステムアーキテクチャを設計することを決定しました。そして\ascii{TensorFlow}が誕生し、深層学習分野の新時代を切り開きました。

\subsubsection{プログラミングモデル}

\ascii{TensorFlow}はデータフローグラフを使用して計算プロセスと共有状態を表現し、ノードを使用して抽象的な計算を表現し、エッジを使用してデータフローを表現します。\refig{tf-dataflow}は、\ascii{MNIST}手書き数字認識アプリケーションのデータフローグラフを示しています。このモデルでは、フォワードサブグラフは\ascii{2}層の全結合ネットワークを使用しており、それぞれ\ascii{ReLU}層と\ascii{Softmax}層です。その後、\ascii{SGD}最適化アルゴリズムを使用して、フォワードサブグラフに対応するバックワードサブグラフを構築し、トレーニングパラメータの勾配を計算します。最後に、パラメータ更新ルールに基づいてトレーニングパラメータの更新サブグラフを構築し、トレーニングパラメータの反復更新を完了します。

\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{figures/tf-dataflow.png}
\caption{TensorFlow: データフローグラフ}
 \label{fig:tf-dataflow}
\end{figure}

\subsubsection{設計原則}

\tf{}のシステムアーキテクチャは、\tf{}のシステム実装を導くいくつかの基本的な設計原則に従っています。

\begin{enum}
  \eitem{遅延計算：グラフの構築と実行を分離し、計算グラフの実行プロセスを遅延させます。}
  \eitem{原子的\ascii{OP}：\ascii{OP}は最小の抽象計算単位であり、複雑なネットワークモデルの構築をサポートします。} 
  \eitem{抽象デバイス：\ascii{CPU、GPU、ASIC}など多様な異種計算デバイスタイプをサポートします。}
  \eitem{抽象タスク：タスクベースの\ascii{PS}は、新しい最適化アルゴリズムとネットワークモデルに対して良好な拡張性を持ちます。}  
\end{enum}

\subsubsection{利点}

他の機械学習フレームワークと比較して、\ascii{TensorFlow}には以下の利点があります。

\begin{enum}
  \eitem{高性能：\tf{}がバージョン\ascii{1.0}にアップグレードされた際、性能が大幅に向上しました。単一マシンのマルチGPU環境（\ascii{8}枚の\ascii{GPU}）で、\ascii{Inception v3}のトレーニングが\ascii{7.3}倍の速度向上を実現しました。分散マルチマシンマルチGPU環境（\ascii{64}枚の\ascii{GPU}）では、\ascii{Inception v3}のトレーニングが\ascii{58}倍の速度向上を実現しました。}
  \eitem{クロスプラットフォーム：マルチ\ascii{CPU/GPU/ASIC}など多様な異種デバイスでの計算をサポートします。デスクトップ、サーバー、モバイルデバイスなど多様な計算プラットフォームをサポートします。\ascii{Windows、Linux、MacOS}など多様なオペレーティングシステムをサポートします。}
  \eitem{分散：ローカルおよび分散モデルのトレーニングと推論をサポートします。}
  \eitem{マルチ言語：\ascii{Python、C++、Java、Go}など多様なプログラミング言語をサポートします。}  
  \eitem{汎用性：フィードフォワード以外のニューラルネットワークを含む、様々な複雑なネットワークモデルの設計と実装をサポートします。}
  \eitem{拡張性：\ascii{OP}拡張、\ascii{Kernel}拡張、\ascii{Device}拡張、通信プロトコルの拡張をサポートします。}
  \eitem{可視化：\ascii{TensorBoard}を使用してトレーニング全体のプロセスを可視化し、\tf{}のデバッグプロセスを大幅に簡素化します。}
  \eitem{自動微分：\tf{}は自動的にバックワード計算サブグラフを構築し、トレーニングパラメータの勾配計算を完了します。}
  \eitem{ワークフロー：\ascii{TensorFlow}は\ascii{TensorFlow Serving}とシームレスに統合され、モデルのトレーニング、インポート、エクスポート、公開のワンストップワークフローをサポートし、モデルのホットアップデートとバージョン管理を自動的に実現します。}      
\end{enum}

\end{content}

\section{コミュニティの発展}

\begin{content}

\tf{}は現在最も注目を集めている深層学習フレームワークです。オープンソース化以来、\tf{}コミュニティは非常に活発です。\ascii{Github}上では\ascii{Google}社員以外からの数万回のコードコミットを受け、毎週約100件の\ascii{Issue}が提出されています。\ascii{Stack Overflow}上でも\tf{}に関する数万の質問が投稿され回答されています。さまざまな技術カンファレンスでも、\tf{}は輝く星として多くの開発者から支持を得ています。

\subsection{オープンソース}

\ascii{2015年11月}、\ascii{Google Research}は記事：\code{\href{https://research.googleblog.com/2015/11/tensorflow-googles-latest-machine\_9.html}{TensorFlow: Google's latest machine learning system, open sourced for everyone}}を発表し、新世代の機械学習システム\ascii{TensorFlow}のオープンソース化を正式に宣言しました。その後、\ascii{TensorFlow}の\ascii{Github}リポジトリは短期間で大量の\ascii{Star}と\ascii{Fork}を獲得しました。\refig{tf-commits}に示すように、\ascii{TensorFlow}のコミュニティの活発さは他の競合製品をはるかに上回り、現在最も人気のある深層学習フレームワークとなっています。

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{figures/tf-commits.png}
\caption{TensorFlow：コミュニティの活発さ}
 \label{fig:tf-commits}
\end{figure}

疑いの余地もなく、\ascii{TensorFlow}のオープンソース化は学術界と産業界に大きな影響を与えました。これにより、各業界での深層学習の応用の難易度が大幅に下がりました。多くの学者、エンジニア、企業、組織が\ascii{TensorFlow}コミュニティに参加し、共に\ascii{TensorFlow}を改善し、その継続的な進化と発展を推進しています。

\subsection{マイルストーン}

\tf{}は\ascii{2015年11月}にオープンソース化されて以来、平均して1ヶ月強に1回のペースでバージョンがリリースされています。\refig{tf-versions}は、\tf{}のいくつかの重要な機能のリリース時期を示しています。

\begin{figure}[!htbp]
\centering
\includegraphics[width=1.0\textwidth]{figures/tf-versions.png}
\caption{TensorFlowの重要なマイルストーン}
 \label{fig:tf-versions}
\end{figure}

\subsection{産業応用}

\ascii{TensorFlow}がオープンソース化されてから2年間で、本番環境で大規模に使用されるようになりました。医療分野では、医師が皮膚がんの発生確率を予測するのを支援しています。音楽や絵画の分野では、人間がアートをより良く理解するのを助けています。モバイル端末では、複数のモバイルデバイスに\ascii{TensorFlow}でトレーニングされた機械学習モデルが搭載され、翻訳作業に使用されています。\ascii{TensorFlow}の\ascii{Google}内部での使用も急速に増加しており、\ascii{Google Search、Google Gmail、Google Translate、Google Maps}など、多くの重要な製品で関連アプリケーションが見られます（\refig{tf-google-apps}参照）。

\begin{figure}[!htbp]
\centering
\includegraphics[width=1.0\textwidth]{figures/tf-google-apps.png}
\caption{TensorFlow：Googleでの内部使用状況}
 \label{fig:tf-google-apps}
\end{figure}

\end{content}
